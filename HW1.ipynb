{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training data: 27441\n",
      "size of testing data: 13515\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv('./data.csv')\n",
    "\n",
    "data_size = dataframe.shape[0]\n",
    "feature_num = dataframe.shape[1] - 1\n",
    "test_size = round(data_size * 0.33)\n",
    "\n",
    "#Split data\n",
    "random.seed(0)\n",
    "indices = dataframe.index.tolist()\n",
    "test_in = random.sample(population = indices, k = test_size)\n",
    "\n",
    "test_df = dataframe.loc[test_in]\n",
    "train_df = dataframe.drop(test_in)\n",
    "\n",
    "# Normalize data\n",
    "def normalize(df):\n",
    "    maxx = df.max()\n",
    "    minn = df.min()\n",
    "    dif = (df-maxx)/(maxx-minn)\n",
    "    return dif\n",
    "\n",
    "X_train_df = normalize(train_df.iloc[:, 0:48])\n",
    "Y_train_df = train_df['48']\n",
    "\n",
    "X_test_df = normalize(test_df.iloc[:, 0:48])\n",
    "Y_test_df = test_df['48'] \n",
    "\n",
    "X_train = X_train_df.to_numpy()\n",
    "Y_train = Y_train_df.to_numpy()\n",
    "X_test = X_test_df.to_numpy()\n",
    "Y_test = Y_test_df.to_numpy()\n",
    "    \n",
    "print(\"size of training data:\",len(X_train))\n",
    "print(\"size of testing data:\", len(X_test))\n",
    "\n",
    "data_train = train_df.to_numpy()\n",
    "data_test = test_df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_find_similarity(X_train, X_test):\n",
    "    norm_test = np.linalg.norm(X_test, axis = 1)\n",
    "    norm_test = np.reshape(norm_test,(-1,1))\n",
    "    norm_train = np.linalg.norm((X_train), axis = 1)\n",
    "    norm_train = np.reshape(norm_train,(1,-1))\n",
    "    \n",
    "    norm = np.dot(norm_test,norm_train) \n",
    "    cos_sim = np.dot(X_test, np.transpose(X_train))/norm\n",
    "    \n",
    "    return cos_sim\n",
    "\n",
    "def KNN_predict(cos_sim,K,Y_train):\n",
    "    Y_pred = []\n",
    "    for row in cos_sim:\n",
    "        votes=[]\n",
    "        index = row.argsort()[::-1][0:K]\n",
    "        for i in index:\n",
    "            votes.append(Y_train[i])\n",
    "        mmax = np.argmax(np.bincount(votes))\n",
    "        Y_pred.append(mmax)\n",
    "    Y_pred = np.asarray(Y_pred)\n",
    "    return Y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Confusion Matrix\n"
=======
    "## K-Means\n"
>>>>>>> 9a370ac28bef9471c118af7fe62c9f3f2b9ef5e7
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = feature_num\n",
    "\n",
    "def confusMax(Y_pred, Y_test):\n",
    "    Y_hold = Y_test * num_class + Y_pred\n",
    "#     Y_hold = np.zeros(num_class * num_class)\n",
    "    Y_bin = np.arange(num_class * num_class + 1)\n",
    "    con_matrx = np.asarray(np.histogram(Y_hold, bins=Y_bin)[0]).reshape(num_class, num_class)\n",
    "#     return np.histogram(Y_hold, bins=Y_bin)\n",
    "    return con_matrx\n",
    "#     print(len(hold))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,  472,   62, ...,    0,    0,    0],\n",
       "       [   0,    2, 1231, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    0,    0, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y1 = np.array([0,1,1,1])\n",
    "# Y2 = np.array([0,1,1,2])\n",
    "\n",
    "Y1 = KNN(X_train,X_test,Y_train,5)\n",
    "\n",
    "confusMax(Y1, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  8  2 ... 11  1  2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(Y1.shape)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Recall and Precision"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find k cluster center\n",
    "#use test set to find which cluster center it similar to \n",
    "def update_centroids(centers, X_train):\n",
    "    #k = len(centers)\n",
    "    k = centers.shape[0]\n",
    "    n = X_train.shape[0]\n",
    "    d = X_train.shape[1]\n",
    "    \n",
    "    #compute l2\n",
    "    aa = np.sum(np.square(centers),axis = 1)\n",
    "    bb = np.sum(np.square(X_train),axis = 1)\n",
    "    aa = np.reshape(aa,(-1,1))\n",
    "    bb = np.reshape(bb,(-1,1))\n",
    "    aa = np.tile(aa,n)\n",
    "    bb = np.tile(bb,k)\n",
    "    bb = np.transpose(bb)\n",
    "    \n",
    "    cc = -2 * np.dot(centers,np.transpose(X_train))\n",
    "    xx = aa + bb + cc\n",
    "    dist = np.sqrt(xx)\n",
    "    colmax = dist.argmax(axis=0)\n",
    "    \n",
    "    new_centers = np.zeros((k,d))\n",
    "    \n",
    "    clusters = [np.zeros((n,d))] * k\n",
    "    \n",
    "    \n",
    "    for i in range(n):\n",
    "        cluster_i = colmax[i]\n",
    "        clusters[cluster_i][i,:]=X_train[i]\n",
    "    \n",
    "    for j in range(k):\n",
    "        new_centers[j] = np.mean(clusters[j],axis=0)\n",
    "    \n",
    "    return new_centers  # k * d"
>>>>>>> 9a370ac28bef9471c118af7fe62c9f3f2b9ef5e7
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall(y_true,y_pred):\n",
    "    con_matrix = confusMax(y_pred,y_true)\n",
    "    num = len(con_matrix)\n",
    "    sum_recall = 0.0\n",
    "    for j in range(num):\n",
    "        TP = 0\n",
    "        FN = 0\n",
    "        for i in range(num):\n",
    "            if(i == j):\n",
    "                TP += con_matrix[i][j]\n",
    "            FN += con_matrix[i][j]\n",
    "        if TP == 0:\n",
    "            sum_recall += 0\n",
    "        else: \n",
    "            sum_recall += (TP/(TP + FN))/feature_num\n",
    "    return sum_recall\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "#      \"\"\"\n",
    "#     :type y_true: numpy.ndarray\n",
    "#     :type y_pred: numpy.ndarray\n",
    "#     :rtype: float\n",
    "#     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0717879652794393"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recall(Y_test, Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
=======
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroids(X_train,K):\n",
    "    d = X_train.shape[1]\n",
    "    \n",
    "    #create a matrix for centers\n",
    "    final_centers = [np.zeros(d)] * K\n",
    "    centers = np.zeros((K,d))\n",
    "    \n",
    "    #if center still change after 10000 times, force stop\n",
    "    itera = 10000\n",
    "    while(itera!=0):\n",
    "        print(itera)\n",
    "        \n",
    "        #initial k centers\n",
    "        if itera == 10000:\n",
    "            #print(\"111111111111\")\n",
    "            ind = random.sample(range(0,len_train),K)\n",
    "            #print(ind)\n",
    "            ii = 0\n",
    "            for i in ind:\n",
    "                centers[ii,:] = X_train[i,:]\n",
    "                ii = ii + 1\n",
    "        #update centers  \n",
    "        new_centers = update_centroids(centers, X_train)\n",
    "        \n",
    "        print(type(new_centers),type(centers),new_centers.shape)       \n",
    "        if ((new_centers == centers).all()):\n",
    "            break\n",
    "\n",
    "        centers = new_centers\n",
    "        itera = itera - 1\n",
    "        \n",
    "    final_centers = new_centers\n",
    "    \n",
    "    return final_centers\n"
   ]
  },
  {
>>>>>>> 9a370ac28bef9471c118af7fe62c9f3f2b9ef5e7
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing:\n",
    "# Bootstrap and make a dataset with size n \n",
    "# choose k features at each time\n",
    "def sampling(data_train, K):\n",
    "    n = len(data_train)\n",
    "    sample_index = []\n",
    "    fea_id = []\n",
    "    \n",
    "    data_sample = []\n",
    "    feature_num = len(data_train[0] - 1)\n",
    "    \n",
    "    while len(fea_id) < K:\n",
    "        fea_id.append(random.randint(0,feature_num-1))\n",
    "    while len(sample_index) < n:\n",
    "        sample_index.append(random.randint(0,n-1))\n",
    "    \n",
    "    for i in sample_index:\n",
    "        sample_one = []\n",
    "        for f in fea_id:\n",
    "            sample_one.append(data_train[i][f])\n",
    "#             collect features \n",
    "#       expend the last colum with target \n",
    "        sample_one.append(data_train[i][-1])\n",
    "#     add this row of data to data_sample\n",
    "        data_sample.append(sample_one)\n",
    "    data_sample = np.asarray(data_sample)\n",
    "    print(data_sample.shape)\n",
    "    print(fea_id)\n",
    "    return data_sample, fea_id\n",
    "           \n",
    "# sampling(data_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1 = np.array([[1,2,3,4],[1,2,3,4],[1,2,3,4]])\n",
    "# sampling(test1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Gini inpurity\n",
    "def getGini(data):\n",
    "    datasum = len(data);\n",
    "    classes = data[:,-1]\n",
    "    counts = {}\n",
    "    gini_inpurity = 1;\n",
    "    for sample in classes:\n",
    "        counts[sample] = counts.get(sample, 0) + 1\n",
    "    for count in counts.values():\n",
    "        gini_inpurity -= (count/datasum)**2\n",
    "    return gini_inpurity    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    '''TreeNode initiator\n",
    "    Includes:\n",
    "    the feature chosen for split on that node;\n",
    "    the value chosen for that feature\n",
    "    （ ？？？）if there is no gain after trying all the features and values\n",
    "        return the node with its tag\n",
    "    (if there is a positive gain, return the pointer of that node)\n",
    "    the right and left pointer\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, fea=-1, value = None, tag = -1, right=None, left=None):\n",
    "        self.feature = feature \n",
    "        self.value = value  \n",
    "        self.tag = tag  \n",
    "        self.right = right  \n",
    "        self.left = left  \n",
    "\n",
    "def buidTree(data, fea_id):\n",
    "\n",
    "    if len(data) == 0:\n",
    "        return none;\n",
    "    if status(data) == 1:\n",
    "        return TreeNode(tag = data[0][-1])    \n",
    "    gini_parent = getGini(data)\n",
    "    best_split = None\n",
    "    best_gain = 0.0\n",
    "    best_sets = None\n",
    "#     choose the best value for a specific feature\n",
    "    \n",
    "    for i in range(0, len(fea_id)):\n",
    "#         for every single feature\n",
    "        f_id = fea_id[i]\n",
    "        features = data[:,i]\n",
    "#     etract numbers for that feature for all the data in dataset\n",
    "        values = []\n",
    "        for i in range(0, len(data)-1):\n",
    "            values.append((features[i]+features[i+1])/2)\n",
    "        for value in values:\n",
    "            set1, set2 = tree_split(data, i, value)\n",
    "            gain = gini_parent - float(getGini(set1) * len(set1)/len(data) + getGini(set2)* len(set2)/len(data))\n",
    "            if gain > bestgain:\n",
    "                best_split = (f_id, value)\n",
    "                best_gain = gain\n",
    "                best_set = (set1, set2)\n",
    "\n",
    "#   When to return the treeNode? \n",
    "    if bestGain > 0:\n",
    "        left = buidTree(best_sets[0], fea_id)\n",
    "        right = buidTree(best_sets[1], fea_id)\n",
    "        return TreeNode(feature = best_split[0], value = best_split[1], right=right, left=left)\n",
    "    else:\n",
    "        return TreeNode(tag = data[0][-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data with two parts by value\n",
    "def tree_split(data, i, value):\n",
    "    set1 = []\n",
    "    set2 = []\n",
    "    for row in data:\n",
    "        if row[i] < value:\n",
    "            set1.append(row)\n",
    "        elif row[i] > value:\n",
    "            set2.append(row)\n",
    "    return set1, set2\n",
    "\n",
    "# return the number of classes\n",
    "def status(data):\n",
    "    count = {}\n",
    "    for i in data[:, -1]:\n",
    "        count[i] = count.get(i, 0) + 1\n",
    "    return len(count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the random forest:\n",
    "# build m trees with k features of each \n",
    "def random_forest(data_train, m):\n",
    "    trees = []\n",
    "    features = []\n",
    "    K = int(math.log(feature_num, 2))\n",
    "    while len(trees) < m:\n",
    "        sample = sampling(data_train, K)[0]\n",
    "        fea_id = sampling(data_train, K)[1]\n",
    "        features.append(fea_id)\n",
    "        trees.append(buidTree(sample, fea_id))   \n",
    "    return trees\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_train, m):\n",
    "    trees = random_forest(data_train, m)\n",
    "    ans = []\n",
    "    for row in data:          \n",
    "        for tree in trees:\n",
    "            ans.append(dfs(tree, row))\n",
    "    return ans\n",
    "        \n",
    "        \n",
    "def dfs(node, row):\n",
    "    if node.tag!= none:\n",
    "        return node.tag\n",
    "    else:\n",
    "        value = node.value\n",
    "        f = node.feature\n",
    "        x = row[f]\n",
    "        if x < value:\n",
    "            dfs(node.left, row)\n",
    "        else:\n",
    "            dfs(node.right, row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27441, 6)\n",
      "[34, 5, 40, 17, 35]\n",
      "(27441, 6)\n",
      "[24, 23, 34, 39, 30]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 27439 is out of bounds for axis 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-6ef8fb00702c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# trees = random_forest(data_train, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-158-f4b431f622c1>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(data_train, m)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrees\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-157-2adac1092e45>\u001b[0m in \u001b[0;36mrandom_forest\u001b[0;34m(data_train, m)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mfea_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfea_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuidTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfea_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-155-d1ad63dfbf93>\u001b[0m in \u001b[0;36mbuidTree\u001b[0;34m(data, fea_id)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mgain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgini_parent\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetGini\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgetGini\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgain\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbestgain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-156-3b816d3fbc25>\u001b[0m in \u001b[0;36mtree_split\u001b[0;34m(data, i, value)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mset2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 27439 is out of bounds for axis 0 with size 6"
     ]
    }
   ],
   "source": [
    "# trees = random_forest(data_train, 2)\n",
    "predict(data_train, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Predicitve_Analytics.py\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def Accuracy(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "def Recall(y_true,y_pred):\n",
    "     \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "\n",
    "def Precision(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "def WCSS(Clusters):\n",
    "    \"\"\"\n",
    "    :Clusters List[numpy.ndarray]\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "def ConfusionMatrix(y_true,y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\"  \n",
    "\n",
    "def KNN(X_train,X_test,Y_train,K):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    :typr K: constant\n",
    "    \n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    cos_sim = KNN_find_similarity(X_train, X_test)\n",
    "    Y_pred = KNN_predict(cos_sim,K,Y_train)\n",
    "    \n",
    "    return Y_pred\n",
    "        \n",
    "def RandomForest(X_train,Y_train,X_test):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "def PCA(X_train,N):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type N: int\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "def Kmeans(X_train,N):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type N: int\n",
    "    :rtype: List[numpy.ndarray]\n",
    "    \"\"\"\n",
    "    centroids = find_centroids(X_train,N)\n",
    "    return centroids\n",
    "\n",
    "def SklearnSupervisedLearning(X_train,Y_train,X_test):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: List[numpy.ndarray] \n",
    "    \"\"\"\n",
    "\n",
    "def SklearnVotingClassifier(X_train,Y_train,X_test):\n",
    "    \n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: List[numpy.ndarray] \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "#\"\"\"\n",
    "#Create your own custom functions for Matplotlib visualization of hyperparameter search. \n",
    "#Make sure that plots are labeled and proper legends are used\n",
    "#\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(Y_true, Y_pred):\n",
    "    count = 0\n",
    "    for i in range(0, len(Y_pred)):\n",
    "        if Y_true[i] == Y_pred[i]:\n",
    "            count += 1\n",
    "    acc = count/len(Y_pred)\n",
    "    print(acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9a15c33d3b2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mK_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mY_pred_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK_knn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0me1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "## KNN\n",
    "K_knn = 11\n",
    "\n",
    "s1 = time.time()\n",
    "Y_pred_knn = KNN(X_train,X_test,Y_train,K_knn)\n",
    "e1 = time.time()\n",
    "\n",
    "Y_pred_knn = np.asarray(Y_pred_knn)\n",
    "acc_knn = Accuracy(Y_test, Y_pred_knn)\n",
    "\n",
    "print(\"Running time of KNN\",e1-s1,\".\")\n",
    "print(\"Accuracy of KNN\",acc_knn,\".\")\n",
    "print(\"=================\")\n",
    "\n",
    "## K-Means\n",
    "K_kmeans = 11\n",
    "\n",
    "s2 = time.time()\n",
    "centroids = Kmeans(X_train,K_kmeans)\n",
    "e2 = time.time()\n",
    "print(\"Runtime of K-Means: \",e2-s2,\"s.\")\n",
    "#print(centroids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-11046684a1b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfeature_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(Y1.shape())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY_pred_knn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY_pred_knn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mY1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "Y1 = Y_test * feature_num\n",
    "# print(Y1.shape())\n",
    "Y1.reshape(1, -1)\n",
    "Y_pred_knn.reshape(1, -1)\n",
    "confu = (Y_pred_knn + Y1)\n",
    "confu.resize(feature_num, feature_num)\n",
    "print(confu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
