{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training data: 27441\n",
      "size of testing data: 13515\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv('./data.csv')\n",
    "\n",
    "data_size = dataframe.shape[0]\n",
    "feature_num = dataframe.shape[1] - 1\n",
    "test_size = round(data_size * 0.33)\n",
    "\n",
    "#Split data\n",
    "random.seed(0)\n",
    "indices = dataframe.index.tolist()\n",
    "test_in = random.sample(population = indices, k = test_size)\n",
    "\n",
    "test_df = dataframe.loc[test_in]\n",
    "train_df = dataframe.drop(test_in)\n",
    "\n",
    "# Normalize data\n",
    "def normalize(df):\n",
    "    maxx = df.max()\n",
    "    minn = df.min()\n",
    "    dif = (df-maxx)/(maxx-minn)\n",
    "    return dif\n",
    "\n",
    "X_train_df = normalize(train_df.iloc[:, 0:48])\n",
    "Y_train_df = train_df['48']\n",
    "\n",
    "X_test_df = normalize(test_df.iloc[:, 0:48])\n",
    "Y_test_df = test_df['48'] \n",
    "\n",
    "X_train = X_train_df.to_numpy()\n",
    "Y_train = Y_train_df.to_numpy()\n",
    "X_test = X_test_df.to_numpy()\n",
    "Y_test = Y_test_df.to_numpy()\n",
    "    \n",
    "print(\"size of training data:\",len(X_train))\n",
    "print(\"size of testing data:\", len(X_test))\n",
    "\n",
    "data_train = train_df.to_numpy()\n",
    "data_test = test_df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_find_similarity(X_train, X_test):\n",
    "    norm_test = np.linalg.norm(X_test, axis = 1)\n",
    "    norm_test = np.reshape(norm_test,(-1,1))\n",
    "    norm_train = np.linalg.norm((X_train), axis = 1)\n",
    "    norm_train = np.reshape(norm_train,(1,-1))\n",
    "    \n",
    "    norm = np.dot(norm_test,norm_train) \n",
    "    cos_sim = np.dot(X_test, np.transpose(X_train))/norm\n",
    "    \n",
    "    return cos_sim\n",
    "\n",
    "def KNN_predict(cos_sim,K,Y_train):\n",
    "    Y_pred = []\n",
    "    for row in cos_sim:\n",
    "        votes=[]\n",
    "        index = row.argsort()[::-1][0:K]\n",
    "        for i in index:\n",
    "            votes.append(Y_train[i])\n",
    "        mmax = np.argmax(np.bincount(votes))\n",
    "        Y_pred.append(mmax)\n",
    "    return Y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find k cluster center\n",
    "#use test set to find which cluster center it similar to \n",
    "def update_centroids(centers, X_train):\n",
    "    #k = len(centers)\n",
    "    k = centers.shape[0]\n",
    "    n = X_train.shape[0]\n",
    "    d = X_train.shape[1]\n",
    "    \n",
    "    #compute l2\n",
    "    aa = np.sum(np.square(centers),axis = 1)\n",
    "    bb = np.sum(np.square(X_train),axis = 1)\n",
    "    aa = np.reshape(aa,(-1,1))\n",
    "    bb = np.reshape(bb,(-1,1))\n",
    "    aa = np.tile(aa,n)\n",
    "    bb = np.tile(bb,k)\n",
    "    bb = np.transpose(bb)\n",
    "    \n",
    "    cc = -2 * np.dot(centers,np.transpose(X_train))\n",
    "    xx = aa + bb + cc\n",
    "    dist = np.sqrt(xx)\n",
    "    colmax = dist.argmax(axis=0)\n",
    "    \n",
    "    new_centers = np.zeros((k,d))\n",
    "    \n",
    "    clusters = [np.zeros((n,d))] * k\n",
    "    \n",
    "    \n",
    "    for i in range(n):\n",
    "        cluster_i = colmax[i]\n",
    "        clusters[cluster_i][i,:]=X_train[i]\n",
    "    \n",
    "    for j in range(k):\n",
    "        new_centers[j] = np.mean(clusters[j],axis=0)\n",
    "    \n",
    "    return new_centers  # k * d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroids(X_train,K):\n",
    "    d = X_train.shape[1]\n",
    "    \n",
    "    #create a matrix for centers\n",
    "    final_centers = [np.zeros(d)] * K\n",
    "    centers = np.zeros((K,d))\n",
    "    \n",
    "    #if center still change after 10000 times, force stop\n",
    "    itera = 10000\n",
    "    while(itera!=0):\n",
    "        print(itera)\n",
    "        \n",
    "        #initial k centers\n",
    "        if itera == 10000:\n",
    "            #print(\"111111111111\")\n",
    "            ind = random.sample(range(0,len_train),K)\n",
    "            #print(ind)\n",
    "            ii = 0\n",
    "            for i in ind:\n",
    "                centers[ii,:] = X_train[i,:]\n",
    "                ii = ii + 1\n",
    "        #update centers  \n",
    "        new_centers = update_centroids(centers, X_train)\n",
    "        \n",
    "        print(type(new_centers),type(centers),new_centers.shape)       \n",
    "        if ((new_centers == centers).all()):\n",
    "            break\n",
    "\n",
    "        centers = new_centers\n",
    "        itera = itera - 1\n",
    "        \n",
    "    final_centers = new_centers\n",
    "    \n",
    "    return final_centers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing:\n",
    "# Bootstrap and make a dataset with size n \n",
    "# ***not dropping any features(class) here\n",
    "def sampling(data_train):\n",
    "    n = len(data_train)\n",
    "    data_sample = []\n",
    "    while len(data_sample) < n:\n",
    "        i = random.randint(0, n-1)\n",
    "        data_sample.append(data_train[i])\n",
    "#         print(i)\n",
    "    print(len(data_sample))\n",
    "    return data_sample\n",
    "        \n",
    "# sampling(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Gini inpurity\n",
    "def getGini(data):\n",
    "    datasum = len(data);\n",
    "    classes = data[:,-1]\n",
    "    counts = {}\n",
    "    gini_inpurity = 1;\n",
    "    for sample in classes:\n",
    "        counts[sample] = counts.get(sample, 0) + 1\n",
    "    for count in counts.values():\n",
    "        gini_inpurity -= (count/datasum)**2\n",
    "    return gini_inpurity    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2777777777777777"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def buidTree(data, k):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(Y_true, Y_pred):\n",
    "    count = 0\n",
    "    for i in range(0, len(Y_pred)):\n",
    "        if Y_true[i] == Y_pred[i]:\n",
    "            count += 1\n",
    "    acc = count/len(Y_pred)\n",
    "    print(acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Predicitve_Analytics.py\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def Accuracy(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "def Recall(y_true,y_pred):\n",
    "     \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "\n",
    "def Precision(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "def WCSS(Clusters):\n",
    "    \"\"\"\n",
    "    :Clusters List[numpy.ndarray]\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "def ConfusionMatrix(y_true,y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\"  \n",
    "\n",
    "def KNN(X_train,X_test,Y_train,K):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    :typr K: constant\n",
    "    \n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    cos_sim = KNN_find_similarity(X_train, X_test)\n",
    "    Y_pred = KNN_predict(cos_sim,K,Y_train)\n",
    "    \n",
    "    return Y_pred\n",
    "        \n",
    "def RandomForest(X_train,Y_train,X_test):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "def PCA(X_train,N):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type N: int\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "def Kmeans(X_train,N):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type N: int\n",
    "    :rtype: List[numpy.ndarray]\n",
    "    \"\"\"\n",
    "    centroids = find_centroids(X_train,N)\n",
    "    return centroids\n",
    "\n",
    "def SklearnSupervisedLearning(X_train,Y_train,X_test):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: List[numpy.ndarray] \n",
    "    \"\"\"\n",
    "\n",
    "def SklearnVotingClassifier(X_train,Y_train,X_test):\n",
    "    \n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: List[numpy.ndarray] \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "#\"\"\"\n",
    "#Create your own custom functions for Matplotlib visualization of hyperparameter search. \n",
    "#Make sure that plots are labeled and proper legends are used\n",
    "#\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9a15c33d3b2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mK_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mY_pred_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK_knn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0me1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "## KNN\n",
    "K_knn = 11\n",
    "\n",
    "s1 = time.time()\n",
    "Y_pred_knn = KNN(X_train,X_test,Y_train,K_knn)\n",
    "e1 = time.time()\n",
    "\n",
    "Y_pred_knn = np.asarray(Y_pred_knn)\n",
    "acc_knn = Accuracy(Y_test, Y_pred_knn)\n",
    "\n",
    "print(\"Running time of KNN\",e1-s1,\".\")\n",
    "print(\"Accuracy of KNN\",acc_knn,\".\")\n",
    "print(\"=================\")\n",
    "\n",
    "## K-Means\n",
    "K_kmeans = 11\n",
    "\n",
    "s2 = time.time()\n",
    "centroids = Kmeans(X_train,K_kmeans)\n",
    "e2 = time.time()\n",
    "print(\"Runtime of K-Means: \",e2-s2,\"s.\")\n",
    "#print(centroids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-11046684a1b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfeature_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(Y1.shape())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY_pred_knn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY_pred_knn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mY1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "Y1 = Y_test * feature_num\n",
    "# print(Y1.shape())\n",
    "Y1.reshape(1, -1)\n",
    "Y_pred_knn.reshape(1, -1)\n",
    "confu = (Y_pred_knn + Y1)\n",
    "confu.resize(feature_num, feature_num)\n",
    "print(confu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
