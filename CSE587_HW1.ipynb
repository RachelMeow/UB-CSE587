{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32765, 48) (32765,)\n",
      "size of training data: 32765\n",
      "size of testing data: 8191\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv('./data.csv')\n",
    "\n",
    "data_size = dataframe.shape[0]\n",
    "feature_num = dataframe.shape[1] - 1\n",
    "test_size = round(data_size * 0.2)\n",
    "#print(test_size)\n",
    "\n",
    "# normalization\n",
    "df = dataframe.iloc[:, 0:48]\n",
    "xmax = df.max()\n",
    "xmin = df.min()\n",
    "\n",
    "dff=(df-xmin)/(xmax-xmin)\n",
    "#print(dff)\n",
    "\n",
    "dataframee = pd.concat([dff,dataframe['48']],axis=1)\n",
    "\n",
    "#Split data\n",
    "random.seed(0)\n",
    "indices = dataframee.index.tolist()\n",
    "#print(indices)\n",
    "test_in = random.sample(population = indices, k = test_size)\n",
    "#print(test_in)\n",
    "\n",
    "test_df = dataframee.loc[test_in]\n",
    "train_df = dataframee.drop(test_in)\n",
    "\n",
    "\n",
    "\n",
    "X_train_df = (train_df.iloc[:, 0:48])\n",
    "Y_train_df = train_df['48']\n",
    "\n",
    "X_test_df = (test_df.iloc[:, 0:48])\n",
    "Y_test_df = test_df['48'] \n",
    "\n",
    "X_train = X_train_df.to_numpy()\n",
    "Y_train = Y_train_df.to_numpy()\n",
    "X_test = X_test_df.to_numpy()\n",
    "Y_test = Y_test_df.to_numpy()\n",
    "\n",
    "print(X_train.shape,Y_train.shape)\n",
    "    \n",
    "print(\"size of training data:\",len(X_train))\n",
    "print(\"size of testing data:\", len(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.596225</td>\n",
       "      <td>0.540284</td>\n",
       "      <td>0.615606</td>\n",
       "      <td>0.838338</td>\n",
       "      <td>0.717266</td>\n",
       "      <td>0.773620</td>\n",
       "      <td>0.710818</td>\n",
       "      <td>0.710995</td>\n",
       "      <td>0.712087</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.012935</td>\n",
       "      <td>0.110421</td>\n",
       "      <td>0.320896</td>\n",
       "      <td>0.364686</td>\n",
       "      <td>0.358736</td>\n",
       "      <td>0.317241</td>\n",
       "      <td>0.344491</td>\n",
       "      <td>0.308625</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.596119</td>\n",
       "      <td>0.541987</td>\n",
       "      <td>0.657480</td>\n",
       "      <td>0.839107</td>\n",
       "      <td>0.714800</td>\n",
       "      <td>0.756745</td>\n",
       "      <td>0.784912</td>\n",
       "      <td>0.785015</td>\n",
       "      <td>0.784224</td>\n",
       "      <td>0.710168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.015774</td>\n",
       "      <td>0.058570</td>\n",
       "      <td>0.464179</td>\n",
       "      <td>0.524752</td>\n",
       "      <td>0.552045</td>\n",
       "      <td>0.228966</td>\n",
       "      <td>0.256625</td>\n",
       "      <td>0.221024</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.596369</td>\n",
       "      <td>0.544879</td>\n",
       "      <td>0.644498</td>\n",
       "      <td>0.839618</td>\n",
       "      <td>0.724341</td>\n",
       "      <td>0.781678</td>\n",
       "      <td>0.688424</td>\n",
       "      <td>0.688369</td>\n",
       "      <td>0.688078</td>\n",
       "      <td>0.533995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.038273</td>\n",
       "      <td>0.148641</td>\n",
       "      <td>0.383582</td>\n",
       "      <td>0.435644</td>\n",
       "      <td>0.444238</td>\n",
       "      <td>0.329655</td>\n",
       "      <td>0.358438</td>\n",
       "      <td>0.320755</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.596565</td>\n",
       "      <td>0.543414</td>\n",
       "      <td>0.630369</td>\n",
       "      <td>0.838824</td>\n",
       "      <td>0.702555</td>\n",
       "      <td>0.798007</td>\n",
       "      <td>0.700639</td>\n",
       "      <td>0.700660</td>\n",
       "      <td>0.701047</td>\n",
       "      <td>0.516568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.006927</td>\n",
       "      <td>0.048715</td>\n",
       "      <td>0.326866</td>\n",
       "      <td>0.372937</td>\n",
       "      <td>0.379182</td>\n",
       "      <td>0.371034</td>\n",
       "      <td>0.400279</td>\n",
       "      <td>0.362534</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.596308</td>\n",
       "      <td>0.545396</td>\n",
       "      <td>0.646339</td>\n",
       "      <td>0.838603</td>\n",
       "      <td>0.722751</td>\n",
       "      <td>0.783740</td>\n",
       "      <td>0.764063</td>\n",
       "      <td>0.763992</td>\n",
       "      <td>0.763704</td>\n",
       "      <td>0.582751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.028285</td>\n",
       "      <td>0.112182</td>\n",
       "      <td>0.391045</td>\n",
       "      <td>0.443894</td>\n",
       "      <td>0.453532</td>\n",
       "      <td>0.325517</td>\n",
       "      <td>0.354254</td>\n",
       "      <td>0.316712</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.596225  0.540284  0.615606  0.838338  0.717266  0.773620  0.710818   \n",
       "1  0.596119  0.541987  0.657480  0.839107  0.714800  0.756745  0.784912   \n",
       "2  0.596369  0.544879  0.644498  0.839618  0.724341  0.781678  0.688424   \n",
       "3  0.596565  0.543414  0.630369  0.838824  0.702555  0.798007  0.700639   \n",
       "4  0.596308  0.545396  0.646339  0.838603  0.722751  0.783740  0.764063   \n",
       "\n",
       "          7         8         9  ...        39        40        41        42  \\\n",
       "0  0.710995  0.712087  0.644000  ...  0.000151  0.012935  0.110421  0.320896   \n",
       "1  0.785015  0.784224  0.710168  ...  0.000240  0.015774  0.058570  0.464179   \n",
       "2  0.688369  0.688078  0.533995  ...  0.000351  0.038273  0.148641  0.383582   \n",
       "3  0.700660  0.701047  0.516568  ...  0.000167  0.006927  0.048715  0.326866   \n",
       "4  0.763992  0.763704  0.582751  ...  0.000350  0.028285  0.112182  0.391045   \n",
       "\n",
       "         43        44        45        46        47  48  \n",
       "0  0.364686  0.358736  0.317241  0.344491  0.308625   5  \n",
       "1  0.524752  0.552045  0.228966  0.256625  0.221024   8  \n",
       "2  0.435644  0.444238  0.329655  0.358438  0.320755   9  \n",
       "3  0.372937  0.379182  0.371034  0.400279  0.362534   9  \n",
       "4  0.443894  0.453532  0.325517  0.354254  0.316712   6  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframee.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_find_similarity(X_train, X_test):\n",
    "    norm_test = np.linalg.norm(X_test, axis = 1)\n",
    "    norm_test = np.reshape(norm_test,(-1,1))\n",
    "    norm_train = np.linalg.norm((X_train), axis = 1)\n",
    "    norm_train = np.reshape(norm_train,(1,-1))\n",
    "    \n",
    "    norm = np.dot(norm_test,norm_train) \n",
    "    cos_sim = np.dot(X_test, np.transpose(X_train))/norm\n",
    "    \n",
    "    return cos_sim\n",
    "\n",
    "def KNN_predict(cos_sim,K,Y_train):\n",
    "    Y_pred = []\n",
    "    for row in cos_sim:\n",
    "        votes=[]\n",
    "        index = row.argsort()[::-1][0:K]\n",
    "        for i in index:\n",
    "            votes.append(Y_train[i])\n",
    "        mmax = np.argmax(np.bincount(votes))\n",
    "        Y_pred.append(mmax)\n",
    "    Y_pred = np.asarray(Y_pred)\n",
    "    return Y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find k cluster center\n",
    "#use test set to find which cluster center it similar to \n",
    "def update_centroids(centers, X_train):\n",
    "    #k = len(centers)\n",
    "    k = centers.shape[0]\n",
    "    n = X_train.shape[0]\n",
    "    d = X_train.shape[1]\n",
    "    \n",
    "    #centers = np.asarray(centers)\n",
    "    #print(centers.shape)\n",
    "    #print(X_train.shape)\n",
    "    #print(\"AAAAAAAAAAAAAAAAAAAA\")\n",
    "    \n",
    "    #compute l2\n",
    "    aa = np.sum(np.square(centers),axis = 1)\n",
    "    bb = np.sum(np.square(X_train),axis = 1)\n",
    "    #print(aa.shape)\n",
    "    #print(bb.shape)\n",
    "    aa = np.reshape(aa,(-1,1))\n",
    "    bb = np.reshape(bb,(-1,1))\n",
    "    #print(aa.shape)\n",
    "    #print(bb.shape)\n",
    "    aa = np.tile(aa,n)\n",
    "    bb = np.tile(bb,k)\n",
    "    bb = np.transpose(bb)\n",
    "    \n",
    "    cc = -2 * np.dot(centers,np.transpose(X_train))\n",
    "    #print(aa.shape)\n",
    "    #print(bb.shape)\n",
    "    #print(cc.shape)\n",
    "    #print(\"BBBBBBBBBBBBBBBBBBBBBB\")\n",
    "    xx = aa + bb + cc\n",
    "    #print(\"bbbbbbbbbbbbbbbbbbbbbbbb\")\n",
    "    dist = np.sqrt(xx)\n",
    "    #print(\"bbbbbbbbbbccccccccccccccc\")\n",
    "    colmax = dist.argmax(axis=0)\n",
    "    #print(\"CCCCCCCCCCCCCCCCCCCCCCCC\")\n",
    "    \n",
    "    \n",
    "    #new_centers = [np.zeros(d)] * k\n",
    "    #new_centers = np.asarray(new_centers)\n",
    "    \n",
    "    #print(\"new_centers\",new_centers.shape)\n",
    "    \n",
    "    new_centers = np.zeros((k,d))\n",
    "    \n",
    "    clusters = [np.zeros((n,d))] * k\n",
    "    \n",
    "    \n",
    "    for i in range(n):\n",
    "        cluster_i = colmax[i]\n",
    "        #clusters[cluster_i].append(X_train[i])\n",
    "        clusters[cluster_i][i,:]=X_train[i]\n",
    "    #print(\"DDDDDDDDDDDDDDDDDDDDD\")\n",
    "    \n",
    "    \n",
    "    #clusters = np.asarray(clusters)\n",
    "    for j in range(k):\n",
    "        new_centers[j] = np.mean(clusters[j],axis=0)\n",
    "    #print(\"EEEEEEEEEEEEEEEEEEEEEEEEE\")\n",
    "    #print(type(new_centers))\n",
    "    \n",
    "    return new_centers  # k * d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroids(X_train,K):\n",
    "    d = X_train.shape[1]\n",
    "    \n",
    "    #create a matrix for centers\n",
    "    final_centers = [np.zeros(d)] * K\n",
    "    #centers = np.asarray(centers)\n",
    "    centers = np.zeros((K,d))\n",
    "    #print(centers.shape)\n",
    "    #print(X_train.shape)\n",
    "    \n",
    "    #if center still change after 10000 times, force stop\n",
    "    itera = 10000\n",
    "    while(itera!=0):\n",
    "        print(itera)\n",
    "        \n",
    "        #initial k centers\n",
    "        if itera == 10000:\n",
    "            #print(\"111111111111\")\n",
    "            ind = random.sample(range(0,len_train),K)\n",
    "            #print(ind)\n",
    "            ii = 0\n",
    "            for i in ind:\n",
    "                centers[ii,:] = X_train[i,:]\n",
    "                ii = ii + 1\n",
    "                #print(X_train[i].shape)\n",
    "                #centers[i] = X_train[i]\n",
    "        #print(\"2222222222222\")\n",
    "        \n",
    "        #update centers  \n",
    "        new_centers = update_centroids(centers, X_train)\n",
    "        #print(\"333333333333333333\")\n",
    "        \n",
    "        print(type(new_centers),type(centers),new_centers.shape)       \n",
    "        if ((new_centers == centers).all()):\n",
    "            #print(\"endendendendendend\")\n",
    "            break\n",
    "        #count = 0\n",
    "        #for i in range(K):\n",
    "        #    if ((new_centers[i]==centers[i]).all()):\n",
    "        #        count = count + 1\n",
    "        #if count == K:\n",
    "        #    break\n",
    "        #print(\"4444444444444444\")\n",
    "        centers = new_centers\n",
    "        itera = itera - 1\n",
    "        \n",
    "    final_centers = new_centers\n",
    "    \n",
    "    return final_centers\n",
    "    #return new_centers"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, N\n",
    "\n",
    "# mean of feature vectors\n",
    "mean_vector = np.mean(X_train,axis = 0)\n",
    "\n",
    "# covariance matrix"
   ]
  },
  {
=======
>>>>>>> 7417b3b2577e5731e6c6735af371ce8f3e509abe
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing:\n",
    "# Bootstrap and make a dataset with size n \n",
    "# choose k features at each time\n",
    "def sampling(data_train, K):\n",
    "    n = len(data_train)\n",
    "    sample_index = []\n",
    "    fea_id = []\n",
    "    \n",
    "    data_sample = []\n",
    "    feature_num = len(data_train[0] - 1)\n",
    "    \n",
    "    while len(fea_id) < K:\n",
    "        fea_id.append(random.randint(0,feature_num-1))\n",
    "    while len(sample_index) < n:\n",
    "        sample_index.append(random.randint(0,n-1))\n",
    "    \n",
    "    for i in sample_index:\n",
    "        sample_one = []\n",
    "        for f in fea_id:\n",
    "            sample_one.append(data_train[i][f])\n",
    "#             collect features \n",
    "#       expend the last colum with target \n",
    "        sample_one.append(data_train[i][-1])\n",
    "#     add this row of data to data_sample\n",
    "        data_sample.append(sample_one)\n",
    "    data_sample = np.asarray(data_sample)\n",
    "    print(data_sample.shape)\n",
    "    print(fea_id)\n",
    "    return data_sample, fea_id\n",
    "           \n",
    "# sampling(data_train, 5)\n",
    "\n",
    "# test1 = np.array([[1,2,3,4],[1,2,3,4],[1,2,3,4]])\n",
    "# sampling(test1, 2)\n",
    "\n",
    "\n",
    "# Calculate Gini inpurity\n",
    "def getGini(data):\n",
    "    print(\"size of data\",data.shape)\n",
    "    datasum = len(data);\n",
    "    if len(data) == 0:\n",
    "        return 0 \n",
    "    classes = data[:,-1]\n",
    "    counts = {}\n",
    "    gini_inpurity = 1;\n",
    "    for sample in classes:\n",
    "        counts[sample] = counts.get(sample, 0) + 1\n",
    "    for count in counts.values():\n",
    "        gini_inpurity -= (count/datasum)**2\n",
    "    return gini_inpurity    \n",
    "\n",
    "class TreeNode:\n",
    "    '''TreeNode initiator\n",
    "    Includes:\n",
    "    the feature chosen for split on that node;\n",
    "    the value chosen for that feature\n",
    "    （ ？？？）if there is no gain after trying all the features and values\n",
    "        return the node with its tag\n",
    "    (if there is a positive gain, return the pointer of that node)\n",
    "    the right and left pointer\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, fea=-1, value = None, tag = -1, right=None, left=None):\n",
    "        self.feature = feature \n",
    "        self.value = value  \n",
    "        self.tag = tag  \n",
    "        self.right = right  \n",
    "        self.left = left  \n",
    "\n",
    "def buidTree(data, fea_id):\n",
    "\n",
    "    if len(data) == 0:\n",
    "        return TreeNode();\n",
    "#     if status(data) == 1:\n",
    "#         return TreeNode(tag = data[0][-1])    \n",
    "    gini_parent = getGini(data)\n",
    "    print(\"gini_parent:\", gini_parent)\n",
    "    best_split = None\n",
    "    best_gain = 0.0\n",
    "    best_sets = None\n",
    "#     choose the best value for a specific feature\n",
    "    \n",
    "    for f in range(0, len(fea_id)):\n",
    "#         for every single feature\n",
    "        f_id = fea_id[f]\n",
    "        print(\"feature id being considered:\", f_id)\n",
    "        data_row = data[:,f]\n",
    "        data_row = np.sort(data_row)\n",
    "#     select numbers for split\n",
    "        values = []\n",
    "        for i in range(0, len(data)-1):\n",
    "            values.append((data_row[i]+data_row[i+1])/2)\n",
    "        print(\"number of values to split:\",len(values))\n",
    "        for value in values:\n",
    "            set1, set2 = tree_split(data, f, value)\n",
    "            gain = gini_parent - float(getGini(set1) * len(set1)/len(data) + getGini(set2)* len(set2)/len(data))\n",
    "            print(\"gain & best gain\", gain, \",\", best_gain)\n",
    "            if gain > best_gain and len(set1) > 0 and len(set2) > 0:\n",
    "                best_split = (f_id, value)\n",
    "                best_gain = gain\n",
    "                best_set = (set1, set2)\n",
    "\n",
    "#   When to return the treeNode? \n",
    "    if best_gain > 0:\n",
    "        print(\"best_gain > 0\")\n",
    "        left = buidTree(best_sets[0], fea_id)\n",
    "        right = buidTree(best_sets[1], fea_id)\n",
    "        return TreeNode(feature = best_split[0], value = best_split[1], right=right, left=left)\n",
    "    else:\n",
    "        return TreeNode(tag = data[0][-1]) \n",
    "\n",
    "    \n",
    "    \n",
    "# split data with two parts by value\n",
    "def tree_split(data, i, value):\n",
    "#     print(\"shape of dataset:\",data.shape)\n",
    "    set1 = []\n",
    "    set2 = []\n",
    "    for row in data:\n",
    "        if row[i] <= value:\n",
    "            set1.append(row)\n",
    "        elif row[i] > value:\n",
    "            set2.append(row)\n",
    "#     print(\"len of my datasets:\", len(set1), \",\", len(set2))\n",
    "    set1 = np.asarray(set1)\n",
    "    set2 = np.asarray(set2)\n",
    "    return set1, set2\n",
    "\n",
    "# return the number of classes\n",
    "def status(data):\n",
    "    count = {}\n",
    "    for i in data[:, -1]:\n",
    "        count[i] = count.get(i, 0) + 1\n",
    "    return len(count)\n",
    "    \n",
    "# Construct the random forest:\n",
    "# build m trees with k features of each \n",
    "def random_forest(data_train, m):\n",
    "    trees = []\n",
    "    features = []\n",
    "    K = int(math.log(feature_num, 2))\n",
    "    while len(trees) < m:\n",
    "        sample = sampling(data_train, K)[0]\n",
    "        fea_id = sampling(data_train, K)[1]\n",
    "        features.append(fea_id)\n",
    "        trees.append(buidTree(sample, fea_id))   \n",
    "    return trees\n",
    "    \n",
    "\n",
    "def predict(x_train, y_train, m):\n",
    "#     print(x_train.shape)\n",
    "#     print(y_train.shape)\n",
    "    data_train =np.concatenate((x_train,y_train.reshape(-1, 1)), axis = 1 )\n",
    "#     x_train.append(y_train)\n",
    "    print(data_train.shape)\n",
    "    trees = random_forest(data_train, m)\n",
    "    ans = []\n",
    "    for row in data:          \n",
    "        for tree in trees:\n",
    "            ans.append(dfs(tree, row))\n",
    "    return ans\n",
    "        \n",
    "        \n",
    "def dfs(node, row):\n",
    "    if node.tag!= none:\n",
    "        return node.tag\n",
    "    else:\n",
    "        value = node.value\n",
    "        f = node.feature\n",
    "        x = row[f]\n",
    "        if x < value:\n",
    "            dfs(node.left, row)\n",
    "        else:\n",
    "            dfs(node.right, row)\n",
    "    \n",
    "\n",
    "# trees = random_forest(data_train, 2)\n",
    "# predict(data_train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 49)\n",
      "(100, 6)\n",
      "[47, 30, 13, 46, 25]\n",
      "(100, 6)\n",
      "[35, 23, 47, 27, 29]\n",
      "size of data (100, 6)\n",
      "gini_parent: 0.8832000000000002\n",
      "feature id being considered: 35\n",
      "number of values to split: 99\n",
      "size of data (2, 6)\n",
      "size of data (98, 6)\n",
      "gain & best gain 0.019118367346938947 , 0.0\n",
      "size of data (2, 6)\n",
      "size of data (98, 6)\n",
      "gain & best gain 0.019118367346938947 , 0.019118367346938947\n",
      "size of data (3, 6)\n",
      "size of data (97, 6)\n",
      "gain & best gain 0.015021305841924515 , 0.019118367346938947\n",
      "size of data (5, 6)\n",
      "size of data (95, 6)\n",
      "gain & best gain 0.013305263157894931 , 0.019118367346938947\n",
      "size of data (5, 6)\n",
      "size of data (95, 6)\n",
      "gain & best gain 0.013305263157894931 , 0.019118367346938947\n",
      "size of data (6, 6)\n",
      "size of data (94, 6)\n",
      "gain & best gain 0.014689361702127757 , 0.019118367346938947\n",
      "size of data (7, 6)\n",
      "size of data (93, 6)\n",
      "gain & best gain 0.018776036866359647 , 0.019118367346938947\n",
      "size of data (10, 6)\n",
      "size of data (90, 6)\n",
      "gain & best gain 0.019200000000000328 , 0.019118367346938947\n",
      "size of data (10, 6)\n",
      "size of data (90, 6)\n",
      "gain & best gain 0.019200000000000328 , 0.019200000000000328\n",
      "size of data (10, 6)\n",
      "size of data (90, 6)\n",
      "gain & best gain 0.019200000000000328 , 0.019200000000000328\n",
      "size of data (12, 6)\n",
      "size of data (88, 6)\n",
      "gain & best gain 0.018881818181818555 , 0.019200000000000328\n",
      "size of data (12, 6)\n",
      "size of data (88, 6)\n",
      "gain & best gain 0.018881818181818555 , 0.019200000000000328\n",
      "size of data (16, 6)\n",
      "size of data (84, 6)\n",
      "gain & best gain 0.010223809523809635 , 0.019200000000000328\n",
      "size of data (16, 6)\n",
      "size of data (84, 6)\n",
      "gain & best gain 0.010223809523809635 , 0.019200000000000328\n",
      "size of data (16, 6)\n",
      "size of data (84, 6)\n",
      "gain & best gain 0.010223809523809635 , 0.019200000000000328\n",
      "size of data (16, 6)\n",
      "size of data (84, 6)\n",
      "gain & best gain 0.010223809523809635 , 0.019200000000000328\n",
      "size of data (19, 6)\n",
      "size of data (81, 6)\n",
      "gain & best gain 0.01449304743339852 , 0.019200000000000328\n",
      "size of data (19, 6)\n",
      "size of data (81, 6)\n",
      "gain & best gain 0.01449304743339852 , 0.019200000000000328\n",
      "size of data (19, 6)\n",
      "size of data (81, 6)\n",
      "gain & best gain 0.01449304743339852 , 0.019200000000000328\n",
      "size of data (21, 6)\n",
      "size of data (79, 6)\n",
      "gain & best gain 0.01661772151898766 , 0.019200000000000328\n",
      "size of data (21, 6)\n",
      "size of data (79, 6)\n",
      "gain & best gain 0.01661772151898766 , 0.019200000000000328\n",
      "size of data (22, 6)\n",
      "size of data (78, 6)\n",
      "gain & best gain 0.015391142191142348 , 0.019200000000000328\n",
      "size of data (23, 6)\n",
      "size of data (77, 6)\n",
      "gain & best gain 0.014549520045172515 , 0.019200000000000328\n",
      "size of data (24, 6)\n",
      "size of data (76, 6)\n",
      "gain & best gain 0.014691228070175755 , 0.019200000000000328\n",
      "size of data (26, 6)\n",
      "size of data (74, 6)\n",
      "gain & best gain 0.01561164241164259 , 0.019200000000000328\n",
      "size of data (26, 6)\n",
      "size of data (74, 6)\n",
      "gain & best gain 0.01561164241164259 , 0.019200000000000328\n",
      "size of data (27, 6)\n",
      "size of data (73, 6)\n",
      "gain & best gain 0.01671598173516009 , 0.019200000000000328\n",
      "size of data (28, 6)\n",
      "size of data (72, 6)\n",
      "gain & best gain 0.016969841269841357 , 0.019200000000000328\n",
      "size of data (33, 6)\n",
      "size of data (67, 6)\n",
      "gain & best gain 0.017401718679330713 , 0.019200000000000328\n",
      "size of data (33, 6)\n",
      "size of data (67, 6)\n",
      "gain & best gain 0.017401718679330713 , 0.019200000000000328\n",
      "size of data (33, 6)\n",
      "size of data (67, 6)\n",
      "gain & best gain 0.017401718679330713 , 0.019200000000000328\n",
      "size of data (33, 6)\n",
      "size of data (67, 6)\n",
      "gain & best gain 0.017401718679330713 , 0.019200000000000328\n",
      "size of data (33, 6)\n",
      "size of data (67, 6)\n",
      "gain & best gain 0.017401718679330713 , 0.019200000000000328\n",
      "size of data (34, 6)\n",
      "size of data (66, 6)\n",
      "gain & best gain 0.01712156862745129 , 0.019200000000000328\n",
      "size of data (36, 6)\n",
      "size of data (64, 6)\n",
      "gain & best gain 0.017088888888889042 , 0.019200000000000328\n",
      "size of data (36, 6)\n",
      "size of data (64, 6)\n",
      "gain & best gain 0.017088888888889042 , 0.019200000000000328\n",
      "size of data (40, 6)\n",
      "size of data (60, 6)\n",
      "gain & best gain 0.01886666666666681 , 0.019200000000000328\n",
      "size of data (40, 6)\n",
      "size of data (60, 6)\n",
      "gain & best gain 0.01886666666666681 , 0.019200000000000328\n",
      "size of data (40, 6)\n",
      "size of data (60, 6)\n",
      "gain & best gain 0.01886666666666681 , 0.019200000000000328\n",
      "size of data (40, 6)\n",
      "size of data (60, 6)\n",
      "gain & best gain 0.01886666666666681 , 0.019200000000000328\n",
      "size of data (43, 6)\n",
      "size of data (57, 6)\n",
      "gain & best gain 0.019903386372909115 , 0.019200000000000328\n",
      "size of data (43, 6)\n",
      "size of data (57, 6)\n",
      "gain & best gain 0.019903386372909115 , 0.019903386372909115\n",
      "size of data (43, 6)\n",
      "size of data (57, 6)\n",
      "gain & best gain 0.019903386372909115 , 0.019903386372909115\n",
      "size of data (45, 6)\n",
      "size of data (55, 6)\n",
      "gain & best gain 0.015361616161616576 , 0.019903386372909115\n",
      "size of data (45, 6)\n",
      "size of data (55, 6)\n",
      "gain & best gain 0.015361616161616576 , 0.019903386372909115\n",
      "size of data (46, 6)\n",
      "size of data (54, 6)\n",
      "gain & best gain 0.015695974235104826 , 0.019903386372909115\n",
      "size of data (49, 6)\n",
      "size of data (51, 6)\n",
      "gain & best gain 0.010074749899960267 , 0.019903386372909115\n",
      "size of data (49, 6)\n",
      "size of data (51, 6)\n",
      "gain & best gain 0.010074749899960267 , 0.019903386372909115\n",
      "size of data (49, 6)\n",
      "size of data (51, 6)\n",
      "gain & best gain 0.010074749899960267 , 0.019903386372909115\n",
      "size of data (50, 6)\n",
      "size of data (50, 6)\n",
      "gain & best gain 0.009600000000000164 , 0.019903386372909115\n",
      "size of data (55, 6)\n",
      "size of data (45, 6)\n",
      "gain & best gain 0.010230303030303256 , 0.019903386372909115\n",
      "size of data (55, 6)\n",
      "size of data (45, 6)\n",
      "gain & best gain 0.010230303030303256 , 0.019903386372909115\n",
      "size of data (55, 6)\n",
      "size of data (45, 6)\n",
      "gain & best gain 0.010230303030303256 , 0.019903386372909115\n",
      "size of data (55, 6)\n",
      "size of data (45, 6)\n",
      "gain & best gain 0.010230303030303256 , 0.019903386372909115\n",
      "size of data (55, 6)\n",
      "size of data (45, 6)\n",
      "gain & best gain 0.010230303030303256 , 0.019903386372909115\n",
      "size of data (58, 6)\n",
      "size of data (42, 6)\n",
      "gain & best gain 0.012313300492611257 , 0.019903386372909115\n",
      "size of data (58, 6)\n",
      "size of data (42, 6)\n",
      "gain & best gain 0.012313300492611257 , 0.019903386372909115\n",
      "size of data (58, 6)\n",
      "size of data (42, 6)\n",
      "gain & best gain 0.012313300492611257 , 0.019903386372909115\n",
      "size of data (61, 6)\n",
      "size of data (39, 6)\n",
      "gain & best gain 0.015507692307692666 , 0.019903386372909115\n",
      "size of data (61, 6)\n",
      "size of data (39, 6)\n",
      "gain & best gain 0.015507692307692666 , 0.019903386372909115\n",
      "size of data (61, 6)\n",
      "size of data (39, 6)\n",
      "gain & best gain 0.015507692307692666 , 0.019903386372909115\n",
      "size of data (62, 6)\n",
      "size of data (38, 6)\n",
      "gain & best gain 0.01635789473684235 , 0.019903386372909115\n",
      "size of data (63, 6)\n",
      "size of data (37, 6)\n",
      "gain & best gain 0.018523895323895534 , 0.019903386372909115\n",
      "size of data (66, 6)\n",
      "size of data (34, 6)\n",
      "gain & best gain 0.020686631016042845 , 0.019903386372909115\n",
      "size of data (66, 6)\n",
      "size of data (34, 6)\n",
      "gain & best gain 0.020686631016042845 , 0.020686631016042845\n",
      "size of data (66, 6)\n",
      "size of data (34, 6)\n",
      "gain & best gain 0.020686631016042845 , 0.020686631016042845\n",
      "size of data (68, 6)\n",
      "size of data (32, 6)\n",
      "gain & best gain 0.02088382352941187 , 0.020686631016042845\n",
      "size of data (68, 6)\n",
      "size of data (32, 6)\n",
      "gain & best gain 0.02088382352941187 , 0.02088382352941187\n",
      "size of data (70, 6)\n",
      "size of data (30, 6)\n",
      "gain & best gain 0.024628571428571444 , 0.02088382352941187\n",
      "size of data (70, 6)\n",
      "size of data (30, 6)\n",
      "gain & best gain 0.024628571428571444 , 0.024628571428571444\n",
      "size of data (71, 6)\n",
      "size of data (29, 6)\n",
      "gain & best gain 0.025220398251578735 , 0.024628571428571444\n",
      "size of data (72, 6)\n",
      "size of data (28, 6)\n",
      "gain & best gain 0.026612698412698754 , 0.025220398251578735\n",
      "size of data (73, 6)\n",
      "size of data (27, 6)\n",
      "gain & best gain 0.02979563673262331 , 0.026612698412698754\n",
      "size of data (74, 6)\n",
      "size of data (26, 6)\n",
      "gain & best gain 0.031058627858628007 , 0.02979563673262331\n",
      "size of data (76, 6)\n",
      "size of data (24, 6)\n",
      "gain & best gain 0.03469122807017577 , 0.031058627858628007\n",
      "size of data (76, 6)\n",
      "size of data (24, 6)\n",
      "gain & best gain 0.03469122807017577 , 0.03469122807017577\n",
      "size of data (79, 6)\n",
      "size of data (21, 6)\n",
      "gain & best gain 0.019089089813140614 , 0.03469122807017577\n",
      "size of data (79, 6)\n",
      "size of data (21, 6)\n",
      "gain & best gain 0.019089089813140614 , 0.03469122807017577\n",
      "size of data (79, 6)\n",
      "size of data (21, 6)\n",
      "gain & best gain 0.019089089813140614 , 0.03469122807017577\n",
      "size of data (81, 6)\n",
      "size of data (19, 6)\n",
      "gain & best gain 0.02196543209876567 , 0.03469122807017577\n",
      "size of data (81, 6)\n",
      "size of data (19, 6)\n",
      "gain & best gain 0.02196543209876567 , 0.03469122807017577\n",
      "size of data (82, 6)\n",
      "size of data (18, 6)\n",
      "gain & best gain 0.017400542005420183 , 0.03469122807017577\n",
      "size of data (84, 6)\n",
      "size of data (16, 6)\n",
      "gain & best gain 0.0249857142857145 , 0.03469122807017577\n",
      "size of data (84, 6)\n",
      "size of data (16, 6)\n",
      "gain & best gain 0.0249857142857145 , 0.03469122807017577\n",
      "size of data (86, 6)\n",
      "size of data (14, 6)\n",
      "gain & best gain 0.017087043189369044 , 0.03469122807017577\n",
      "size of data (86, 6)\n",
      "size of data (14, 6)\n",
      "gain & best gain 0.017087043189369044 , 0.03469122807017577\n",
      "size of data (90, 6)\n",
      "size of data (10, 6)\n",
      "gain & best gain 0.013866666666667027 , 0.03469122807017577\n",
      "size of data (90, 6)\n",
      "size of data (10, 6)\n",
      "gain & best gain 0.013866666666667027 , 0.03469122807017577\n",
      "size of data (90, 6)\n",
      "size of data (10, 6)\n",
      "gain & best gain 0.013866666666667027 , 0.03469122807017577\n",
      "size of data (90, 6)\n",
      "size of data (10, 6)\n",
      "gain & best gain 0.013866666666667027 , 0.03469122807017577\n",
      "size of data (91, 6)\n",
      "size of data (9, 6)\n",
      "gain & best gain 0.017705494505494745 , 0.03469122807017577\n",
      "size of data (95, 6)\n",
      "size of data (5, 6)\n",
      "gain & best gain 0.017094736842105274 , 0.03469122807017577\n",
      "size of data (95, 6)\n",
      "size of data (5, 6)\n",
      "gain & best gain 0.017094736842105274 , 0.03469122807017577\n",
      "size of data (95, 6)\n",
      "size of data (5, 6)\n",
      "gain & best gain 0.017094736842105274 , 0.03469122807017577\n",
      "size of data (95, 6)\n",
      "size of data (5, 6)\n",
      "gain & best gain 0.017094736842105274 , 0.03469122807017577\n",
      "size of data (98, 6)\n",
      "size of data (2, 6)\n",
      "gain & best gain 0.008710204081632922 , 0.03469122807017577\n",
      "size of data (98, 6)\n",
      "size of data (2, 6)\n",
      "gain & best gain 0.008710204081632922 , 0.03469122807017577\n",
      "size of data (98, 6)\n",
      "size of data (2, 6)\n",
      "gain & best gain 0.008710204081632922 , 0.03469122807017577\n",
      "size of data (100, 6)\n",
      "size of data (0,)\n",
      "gain & best gain 0.0 , 0.03469122807017577\n",
      "feature id being considered: 23\n",
      "number of values to split: 99\n",
      "size of data (1, 6)\n",
      "size of data (99, 6)\n",
      "gain & best gain 0.010674747474747615 , 0.03469122807017577\n",
      "size of data (3, 6)\n",
      "size of data (97, 6)\n",
      "gain & best gain 0.018114089347079254 , 0.03469122807017577\n",
      "size of data (3, 6)\n",
      "size of data (97, 6)\n",
      "gain & best gain 0.018114089347079254 , 0.03469122807017577\n",
      "size of data (5, 6)\n",
      "size of data (95, 6)\n",
      "gain & best gain 0.01604210526315808 , 0.03469122807017577\n",
      "size of data (5, 6)\n",
      "size of data (95, 6)\n",
      "gain & best gain 0.01604210526315808 , 0.03469122807017577\n",
      "size of data (6, 6)\n",
      "size of data (94, 6)\n",
      "gain & best gain 0.02206524822695055 , 0.03469122807017577\n",
      "size of data (7, 6)\n",
      "size of data (93, 6)\n",
      "gain & best gain 0.029651612903225932 , 0.03469122807017577\n",
      "size of data (8, 6)\n",
      "size of data (92, 6)\n",
      "gain & best gain 0.02656956521739151 , 0.03469122807017577\n",
      "size of data (10, 6)\n",
      "size of data (90, 6)\n",
      "gain & best gain 0.03031111111111162 , 0.03469122807017577\n",
      "size of data (10, 6)\n",
      "size of data (90, 6)\n",
      "gain & best gain 0.03031111111111162 , 0.03469122807017577\n",
      "size of data (12, 6)\n",
      "size of data (88, 6)\n",
      "gain & best gain 0.026912121212121498 , 0.03469122807017577\n",
      "size of data (12, 6)\n",
      "size of data (88, 6)\n",
      "gain & best gain 0.026912121212121498 , 0.03469122807017577\n",
      "size of data (14, 6)\n",
      "size of data (86, 6)\n",
      "gain & best gain 0.034628571428571675 , 0.03469122807017577\n",
      "size of data (14, 6)\n",
      "size of data (86, 6)\n",
      "gain & best gain 0.034628571428571675 , 0.03469122807017577\n",
      "size of data (16, 6)\n",
      "size of data (84, 6)\n",
      "gain & best gain 0.04575952380952386 , 0.03469122807017577\n",
      "size of data (16, 6)\n",
      "size of data (84, 6)\n",
      "gain & best gain 0.04575952380952386 , 0.04575952380952386\n",
      "size of data (17, 6)\n",
      "size of data (83, 6)\n",
      "gain & best gain 0.04076201275691016 , 0.04575952380952386\n",
      "size of data (19, 6)\n",
      "size of data (81, 6)\n",
      "gain & best gain 0.03418115659519183 , 0.04575952380952386\n",
      "size of data (19, 6)\n",
      "size of data (81, 6)\n",
      "gain & best gain 0.03418115659519183 , 0.04575952380952386\n",
      "size of data (22, 6)\n",
      "size of data (78, 6)\n",
      "gain & best gain 0.02804848484848521 , 0.04575952380952386\n",
      "size of data (22, 6)\n",
      "size of data (78, 6)\n",
      "gain & best gain 0.02804848484848521 , 0.04575952380952386\n",
      "size of data (22, 6)\n",
      "size of data (78, 6)\n",
      "gain & best gain 0.02804848484848521 , 0.04575952380952386\n",
      "size of data (23, 6)\n",
      "size of data (77, 6)\n",
      "gain & best gain 0.02665567476002284 , 0.04575952380952386\n",
      "size of data (27, 6)\n",
      "size of data (73, 6)\n",
      "gain & best gain 0.03154094368340965 , 0.04575952380952386\n",
      "size of data (27, 6)\n",
      "size of data (73, 6)\n",
      "gain & best gain 0.03154094368340965 , 0.04575952380952386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of data (27, 6)\n",
      "size of data (73, 6)\n",
      "gain & best gain 0.03154094368340965 , 0.04575952380952386\n",
      "size of data (27, 6)\n",
      "size of data (73, 6)\n",
      "gain & best gain 0.03154094368340965 , 0.04575952380952386\n",
      "size of data (28, 6)\n",
      "size of data (72, 6)\n",
      "gain & best gain 0.02839841269841281 , 0.04575952380952386\n",
      "size of data (31, 6)\n",
      "size of data (69, 6)\n",
      "gain & best gain 0.02801533426835001 , 0.04575952380952386\n",
      "size of data (31, 6)\n",
      "size of data (69, 6)\n",
      "gain & best gain 0.02801533426835001 , 0.04575952380952386\n",
      "size of data (31, 6)\n",
      "size of data (69, 6)\n",
      "gain & best gain 0.02801533426835001 , 0.04575952380952386\n",
      "size of data (34, 6)\n",
      "size of data (66, 6)\n",
      "gain & best gain 0.02412691622103391 , 0.04575952380952386\n",
      "size of data (34, 6)\n",
      "size of data (66, 6)\n",
      "gain & best gain 0.02412691622103391 , 0.04575952380952386\n",
      "size of data (34, 6)\n",
      "size of data (66, 6)\n",
      "gain & best gain 0.02412691622103391 , 0.04575952380952386\n",
      "size of data (37, 6)\n",
      "size of data (63, 6)\n",
      "gain & best gain 0.013719090519090926 , 0.04575952380952386\n",
      "size of data (37, 6)\n",
      "size of data (63, 6)\n",
      "gain & best gain 0.013719090519090926 , 0.04575952380952386\n",
      "size of data (37, 6)\n",
      "size of data (63, 6)\n",
      "gain & best gain 0.013719090519090926 , 0.04575952380952386\n",
      "size of data (39, 6)\n",
      "size of data (61, 6)\n",
      "gain & best gain 0.017844808743169627 , 0.04575952380952386\n",
      "size of data (39, 6)\n",
      "size of data (61, 6)\n",
      "gain & best gain 0.017844808743169627 , 0.04575952380952386\n",
      "size of data (41, 6)\n",
      "size of data (59, 6)\n",
      "gain & best gain 0.021885407193055095 , 0.04575952380952386\n",
      "size of data (41, 6)\n",
      "size of data (59, 6)\n",
      "gain & best gain 0.021885407193055095 , 0.04575952380952386\n",
      "size of data (43, 6)\n",
      "size of data (57, 6)\n",
      "gain & best gain 0.028544757241942276 , 0.04575952380952386\n",
      "size of data (43, 6)\n",
      "size of data (57, 6)\n",
      "gain & best gain 0.028544757241942276 , 0.04575952380952386\n",
      "size of data (44, 6)\n",
      "size of data (56, 6)\n",
      "gain & best gain 0.02868701298701337 , 0.04575952380952386\n",
      "size of data (45, 6)\n",
      "size of data (55, 6)\n",
      "gain & best gain 0.028250505050505414 , 0.04575952380952386\n",
      "size of data (46, 6)\n",
      "size of data (54, 6)\n",
      "gain & best gain 0.029657326892109648 , 0.04575952380952386\n",
      "size of data (47, 6)\n",
      "size of data (53, 6)\n",
      "gain & best gain 0.030482215977519322 , 0.04575952380952386\n",
      "size of data (49, 6)\n",
      "size of data (51, 6)\n",
      "gain & best gain 0.025464905962385154 , 0.04575952380952386\n",
      "size of data (49, 6)\n",
      "size of data (51, 6)\n",
      "gain & best gain 0.025464905962385154 , 0.04575952380952386\n",
      "size of data (50, 6)\n",
      "size of data (50, 6)\n",
      "gain & best gain 0.023600000000000065 , 0.04575952380952386\n",
      "size of data (51, 6)\n",
      "size of data (49, 6)\n",
      "gain & best gain 0.02090308123249307 , 0.04575952380952386\n",
      "size of data (53, 6)\n",
      "size of data (47, 6)\n",
      "gain & best gain 0.019402328382176037 , 0.04575952380952386\n",
      "size of data (53, 6)\n",
      "size of data (47, 6)\n",
      "gain & best gain 0.019402328382176037 , 0.04575952380952386\n",
      "size of data (55, 6)\n",
      "size of data (45, 6)\n",
      "gain & best gain 0.02227070707070733 , 0.04575952380952386\n",
      "size of data (55, 6)\n",
      "size of data (45, 6)\n",
      "gain & best gain 0.02227070707070733 , 0.04575952380952386\n",
      "size of data (57, 6)\n",
      "size of data (43, 6)\n",
      "gain & best gain 0.025264463484292454 , 0.04575952380952386\n",
      "size of data (57, 6)\n",
      "size of data (43, 6)\n",
      "gain & best gain 0.025264463484292454 , 0.04575952380952386\n",
      "size of data (58, 6)\n",
      "size of data (42, 6)\n",
      "gain & best gain 0.023183579638752394 , 0.04575952380952386\n",
      "size of data (60, 6)\n",
      "size of data (40, 6)\n",
      "gain & best gain 0.021533333333333515 , 0.04575952380952386\n",
      "size of data (60, 6)\n",
      "size of data (40, 6)\n",
      "gain & best gain 0.021533333333333515 , 0.04575952380952386\n",
      "size of data (61, 6)\n",
      "size of data (39, 6)\n",
      "gain & best gain 0.023922992854140568 , 0.04575952380952386\n",
      "size of data (62, 6)\n",
      "size of data (38, 6)\n",
      "gain & best gain 0.023947028862478903 , 0.04575952380952386\n",
      "size of data (63, 6)\n",
      "size of data (37, 6)\n",
      "gain & best gain 0.02701810381810399 , 0.04575952380952386\n",
      "size of data (64, 6)\n",
      "size of data (36, 6)\n",
      "gain & best gain 0.024172222222222484 , 0.04575952380952386\n",
      "size of data (65, 6)\n",
      "size of data (35, 6)\n",
      "gain & best gain 0.02201318681318698 , 0.04575952380952386\n",
      "size of data (66, 6)\n",
      "size of data (34, 6)\n",
      "gain & best gain 0.02562424242424255 , 0.04575952380952386\n",
      "size of data (67, 6)\n",
      "size of data (33, 6)\n",
      "gain & best gain 0.02737910447761205 , 0.04575952380952386\n",
      "size of data (68, 6)\n",
      "size of data (32, 6)\n",
      "gain & best gain 0.027905882352941447 , 0.04575952380952386\n",
      "size of data (70, 6)\n",
      "size of data (30, 6)\n",
      "gain & best gain 0.022247619047619294 , 0.04575952380952386\n",
      "size of data (70, 6)\n",
      "size of data (30, 6)\n",
      "gain & best gain 0.022247619047619294 , 0.04575952380952386\n",
      "size of data (73, 6)\n",
      "size of data (27, 6)\n",
      "gain & best gain 0.02017615423642849 , 0.04575952380952386\n",
      "size of data (73, 6)\n",
      "size of data (27, 6)\n",
      "gain & best gain 0.02017615423642849 , 0.04575952380952386\n",
      "size of data (73, 6)\n",
      "size of data (27, 6)\n",
      "gain & best gain 0.02017615423642849 , 0.04575952380952386\n",
      "size of data (74, 6)\n",
      "size of data (26, 6)\n",
      "gain & best gain 0.021412058212058493 , 0.04575952380952386\n",
      "size of data (75, 6)\n",
      "size of data (25, 6)\n",
      "gain & best gain 0.023733333333333606 , 0.04575952380952386\n",
      "size of data (76, 6)\n",
      "size of data (24, 6)\n",
      "gain & best gain 0.026094736842105393 , 0.04575952380952386\n",
      "size of data (78, 6)\n",
      "size of data (22, 6)\n",
      "gain & best gain 0.029959906759907007 , 0.04575952380952386\n",
      "size of data (78, 6)\n",
      "size of data (22, 6)\n",
      "gain & best gain 0.029959906759907007 , 0.04575952380952386\n",
      "size of data (80, 6)\n",
      "size of data (20, 6)\n",
      "gain & best gain 0.02420000000000011 , 0.04575952380952386\n",
      "size of data (80, 6)\n",
      "size of data (20, 6)\n",
      "gain & best gain 0.02420000000000011 , 0.04575952380952386\n",
      "size of data (83, 6)\n",
      "size of data (17, 6)\n",
      "gain & best gain 0.02284564138908607 , 0.04575952380952386\n",
      "size of data (83, 6)\n",
      "size of data (17, 6)\n",
      "gain & best gain 0.02284564138908607 , 0.04575952380952386\n",
      "size of data (83, 6)\n",
      "size of data (17, 6)\n",
      "gain & best gain 0.02284564138908607 , 0.04575952380952386\n",
      "size of data (85, 6)\n",
      "size of data (15, 6)\n",
      "gain & best gain 0.014023529411764768 , 0.04575952380952386\n",
      "size of data (85, 6)\n",
      "size of data (15, 6)\n",
      "gain & best gain 0.014023529411764768 , 0.04575952380952386\n",
      "size of data (87, 6)\n",
      "size of data (13, 6)\n",
      "gain & best gain 0.009601414677276932 , 0.04575952380952386\n",
      "size of data (87, 6)\n",
      "size of data (13, 6)\n",
      "gain & best gain 0.009601414677276932 , 0.04575952380952386\n",
      "size of data (88, 6)\n",
      "size of data (12, 6)\n",
      "gain & best gain 0.009563636363636774 , 0.04575952380952386\n",
      "size of data (89, 6)\n",
      "size of data (11, 6)\n",
      "gain & best gain 0.010268437180796841 , 0.04575952380952386\n",
      "size of data (90, 6)\n",
      "size of data (10, 6)\n",
      "gain & best gain 0.012977777777778088 , 0.04575952380952386\n",
      "size of data (92, 6)\n",
      "size of data (8, 6)\n",
      "gain & best gain 0.012330434782609201 , 0.04575952380952386\n",
      "size of data (92, 6)\n",
      "size of data (8, 6)\n",
      "gain & best gain 0.012330434782609201 , 0.04575952380952386\n",
      "size of data (93, 6)\n",
      "size of data (7, 6)\n",
      "gain & best gain 0.009559447004608312 , 0.04575952380952386\n",
      "size of data (94, 6)\n",
      "size of data (6, 6)\n",
      "gain & best gain 0.011994326241134945 , 0.04575952380952386\n",
      "size of data (96, 6)\n",
      "size of data (4, 6)\n",
      "gain & best gain 0.01382500000000031 , 0.04575952380952386\n",
      "size of data (96, 6)\n",
      "size of data (4, 6)\n",
      "gain & best gain 0.01382500000000031 , 0.04575952380952386\n",
      "size of data (97, 6)\n",
      "size of data (3, 6)\n",
      "gain & best gain 0.017495532646048084 , 0.04575952380952386\n",
      "size of data (98, 6)\n",
      "size of data (2, 6)\n",
      "gain & best gain 0.02156734693877571 , 0.04575952380952386\n",
      "size of data (99, 6)\n",
      "size of data (1, 6)\n",
      "gain & best gain 0.010674747474747615 , 0.04575952380952386\n",
      "feature id being considered: 47\n",
      "number of values to split: 99\n",
      "size of data (1, 6)\n",
      "size of data (99, 6)\n",
      "gain & best gain 0.008452525252525489 , 0.04575952380952386\n",
      "size of data (3, 6)\n",
      "size of data (97, 6)\n",
      "gain & best gain 0.025880412371134254 , 0.04575952380952386\n",
      "size of data (3, 6)\n",
      "size of data (97, 6)\n",
      "gain & best gain 0.025880412371134254 , 0.04575952380952386\n",
      "size of data (5, 6)\n",
      "size of data (95, 6)\n",
      "gain & best gain 0.01835789473684246 , 0.04575952380952386\n",
      "size of data (5, 6)\n",
      "size of data (95, 6)\n",
      "gain & best gain 0.01835789473684246 , 0.04575952380952386\n",
      "size of data (7, 6)\n",
      "size of data (93, 6)\n",
      "gain & best gain 0.017270660522273662 , 0.04575952380952386\n",
      "size of data (7, 6)\n",
      "size of data (93, 6)\n",
      "gain & best gain 0.017270660522273662 , 0.04575952380952386\n",
      "size of data (8, 6)\n",
      "size of data (92, 6)\n",
      "gain & best gain 0.014830434782608815 , 0.04575952380952386\n",
      "size of data (9, 6)\n",
      "size of data (91, 6)\n",
      "gain & best gain 0.01633797313797336 , 0.04575952380952386\n",
      "size of data (10, 6)\n",
      "size of data (90, 6)\n",
      "gain & best gain 0.014977777777777979 , 0.04575952380952386\n",
      "size of data (11, 6)\n",
      "size of data (89, 6)\n",
      "gain & best gain 0.014354239019407689 , 0.04575952380952386\n",
      "size of data (13, 6)\n",
      "size of data (87, 6)\n",
      "gain & best gain 0.0210603006189215 , 0.04575952380952386\n",
      "size of data (13, 6)\n",
      "size of data (87, 6)\n",
      "gain & best gain 0.0210603006189215 , 0.04575952380952386\n",
      "size of data (14, 6)\n",
      "size of data (86, 6)\n",
      "gain & best gain 0.02592425249169461 , 0.04575952380952386\n",
      "size of data (16, 6)\n",
      "size of data (84, 6)\n",
      "gain & best gain 0.025461904761904908 , 0.04575952380952386\n",
      "size of data (16, 6)\n",
      "size of data (84, 6)\n",
      "gain & best gain 0.025461904761904908 , 0.04575952380952386\n",
      "size of data (18, 6)\n",
      "size of data (82, 6)\n",
      "gain & best gain 0.01875555555555586 , 0.04575952380952386\n",
      "size of data (18, 6)\n",
      "size of data (82, 6)\n",
      "gain & best gain 0.01875555555555586 , 0.04575952380952386\n",
      "size of data (20, 6)\n",
      "size of data (80, 6)\n",
      "gain & best gain 0.01570000000000016 , 0.04575952380952386\n",
      "size of data (20, 6)\n",
      "size of data (80, 6)\n",
      "gain & best gain 0.01570000000000016 , 0.04575952380952386\n",
      "size of data (21, 6)\n",
      "size of data (79, 6)\n",
      "gain & best gain 0.012639421338155876 , 0.04575952380952386\n",
      "size of data (23, 6)\n",
      "size of data (77, 6)\n",
      "gain & best gain 0.010054884246188722 , 0.04575952380952386\n",
      "size of data (23, 6)\n",
      "size of data (77, 6)\n",
      "gain & best gain 0.010054884246188722 , 0.04575952380952386\n",
      "size of data (24, 6)\n",
      "size of data (76, 6)\n",
      "gain & best gain 0.00841929824561427 , 0.04575952380952386\n",
      "size of data (25, 6)\n",
      "size of data (75, 6)\n",
      "gain & best gain 0.009600000000000275 , 0.04575952380952386\n",
      "size of data (28, 6)\n",
      "size of data (72, 6)\n",
      "gain & best gain 0.005700000000000149 , 0.04575952380952386\n",
      "size of data (28, 6)\n",
      "size of data (72, 6)\n",
      "gain & best gain 0.005700000000000149 , 0.04575952380952386\n",
      "size of data (28, 6)\n",
      "size of data (72, 6)\n",
      "gain & best gain 0.005700000000000149 , 0.04575952380952386\n",
      "size of data (29, 6)\n",
      "size of data (71, 6)\n",
      "gain & best gain 0.004618164157358162 , 0.04575952380952386\n",
      "size of data (30, 6)\n",
      "size of data (70, 6)\n",
      "gain & best gain 0.004819047619047945 , 0.04575952380952386\n",
      "size of data (31, 6)\n",
      "size of data (69, 6)\n",
      "gain & best gain 0.00449967274427332 , 0.04575952380952386\n",
      "size of data (33, 6)\n",
      "size of data (67, 6)\n",
      "gain & best gain 0.0030462234283131773 , 0.04575952380952386\n",
      "size of data (33, 6)\n",
      "size of data (67, 6)\n",
      "gain & best gain 0.0030462234283131773 , 0.04575952380952386\n",
      "size of data (34, 6)\n",
      "size of data (66, 6)\n",
      "gain & best gain 0.003520855614973506 , 0.04575952380952386\n",
      "size of data (38, 6)\n",
      "size of data (62, 6)\n",
      "gain & best gain 0.007716129032258268 , 0.04575952380952386\n",
      "size of data (38, 6)\n",
      "size of data (62, 6)\n",
      "gain & best gain 0.007716129032258268 , 0.04575952380952386\n",
      "size of data (38, 6)\n",
      "size of data (62, 6)\n",
      "gain & best gain 0.007716129032258268 , 0.04575952380952386\n",
      "size of data (38, 6)\n",
      "size of data (62, 6)\n",
      "gain & best gain 0.007716129032258268 , 0.04575952380952386\n",
      "size of data (39, 6)\n",
      "size of data (61, 6)\n",
      "gain & best gain 0.007319377889870027 , 0.04575952380952386\n",
      "size of data (42, 6)\n",
      "size of data (58, 6)\n",
      "gain & best gain 0.00682889983579682 , 0.04575952380952386\n",
      "size of data (42, 6)\n",
      "size of data (58, 6)\n",
      "gain & best gain 0.00682889983579682 , 0.04575952380952386\n",
      "size of data (42, 6)\n",
      "size of data (58, 6)\n",
      "gain & best gain 0.00682889983579682 , 0.04575952380952386\n",
      "size of data (44, 6)\n",
      "size of data (56, 6)\n",
      "gain & best gain 0.006057142857142983 , 0.04575952380952386\n",
      "size of data (44, 6)\n",
      "size of data (56, 6)\n",
      "gain & best gain 0.006057142857142983 , 0.04575952380952386\n",
      "size of data (45, 6)\n",
      "size of data (55, 6)\n",
      "gain & best gain 0.005462626262626502 , 0.04575952380952386\n",
      "size of data (46, 6)\n",
      "size of data (54, 6)\n",
      "gain & best gain 0.006629951690821478 , 0.04575952380952386\n",
      "size of data (48, 6)\n",
      "size of data (52, 6)\n",
      "gain & best gain 0.008007692307692604 , 0.04575952380952386\n",
      "size of data (48, 6)\n",
      "size of data (52, 6)\n",
      "gain & best gain 0.008007692307692604 , 0.04575952380952386\n",
      "size of data (51, 6)\n",
      "size of data (49, 6)\n",
      "gain & best gain 0.00961056422569051 , 0.04575952380952386\n",
      "size of data (51, 6)\n",
      "size of data (49, 6)\n",
      "gain & best gain 0.00961056422569051 , 0.04575952380952386\n",
      "size of data (51, 6)\n",
      "size of data (49, 6)\n",
      "gain & best gain 0.00961056422569051 , 0.04575952380952386\n",
      "size of data (54, 6)\n",
      "size of data (46, 6)\n",
      "gain & best gain 0.014745893719806835 , 0.04575952380952386\n",
      "size of data (54, 6)\n",
      "size of data (46, 6)\n",
      "gain & best gain 0.014745893719806835 , 0.04575952380952386\n",
      "size of data (54, 6)\n",
      "size of data (46, 6)\n",
      "gain & best gain 0.014745893719806835 , 0.04575952380952386\n",
      "size of data (55, 6)\n",
      "size of data (45, 6)\n",
      "gain & best gain 0.0160484848484852 , 0.04575952380952386\n",
      "size of data (56, 6)\n",
      "size of data (44, 6)\n",
      "gain & best gain 0.01307012987013012 , 0.04575952380952386\n",
      "size of data (59, 6)\n",
      "size of data (41, 6)\n",
      "gain & best gain 0.008243406366267303 , 0.04575952380952386\n",
      "size of data (59, 6)\n",
      "size of data (41, 6)\n",
      "gain & best gain 0.008243406366267303 , 0.04575952380952386\n",
      "size of data (59, 6)\n",
      "size of data (41, 6)\n",
      "gain & best gain 0.008243406366267303 , 0.04575952380952386\n",
      "size of data (60, 6)\n",
      "size of data (40, 6)\n",
      "gain & best gain 0.01003333333333345 , 0.04575952380952386\n",
      "size of data (62, 6)\n",
      "size of data (38, 6)\n",
      "gain & best gain 0.00827640067911739 , 0.04575952380952386\n",
      "size of data (62, 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of data (38, 6)\n",
      "gain & best gain 0.00827640067911739 , 0.04575952380952386\n",
      "size of data (63, 6)\n",
      "size of data (37, 6)\n",
      "gain & best gain 0.007798884598884781 , 0.04575952380952386\n",
      "size of data (64, 6)\n",
      "size of data (36, 6)\n",
      "gain & best gain 0.009866666666666801 , 0.04575952380952386\n",
      "size of data (66, 6)\n",
      "size of data (34, 6)\n",
      "gain & best gain 0.006800713012477866 , 0.04575952380952386\n",
      "size of data (66, 6)\n",
      "size of data (34, 6)\n",
      "gain & best gain 0.006800713012477866 , 0.04575952380952386\n",
      "size of data (68, 6)\n",
      "size of data (32, 6)\n",
      "gain & best gain 0.008567647058823624 , 0.04575952380952386\n",
      "size of data (68, 6)\n",
      "size of data (32, 6)\n",
      "gain & best gain 0.008567647058823624 , 0.04575952380952386\n",
      "size of data (70, 6)\n",
      "size of data (30, 6)\n",
      "gain & best gain 0.007961904761904948 , 0.04575952380952386\n",
      "size of data (70, 6)\n",
      "size of data (30, 6)\n",
      "gain & best gain 0.007961904761904948 , 0.04575952380952386\n",
      "size of data (71, 6)\n",
      "size of data (29, 6)\n",
      "gain & best gain 0.006997960174842444 , 0.04575952380952386\n",
      "size of data (73, 6)\n",
      "size of data (27, 6)\n",
      "gain & best gain 0.009481075596144084 , 0.04575952380952386\n",
      "size of data (73, 6)\n",
      "size of data (27, 6)\n",
      "gain & best gain 0.009481075596144084 , 0.04575952380952386\n",
      "size of data (75, 6)\n",
      "size of data (25, 6)\n",
      "gain & best gain 0.014133333333333664 , 0.04575952380952386\n",
      "size of data (75, 6)\n",
      "size of data (25, 6)\n",
      "gain & best gain 0.014133333333333664 , 0.04575952380952386\n",
      "size of data (76, 6)\n",
      "size of data (24, 6)\n",
      "gain & best gain 0.017980701754386375 , 0.04575952380952386\n",
      "size of data (78, 6)\n",
      "size of data (22, 6)\n",
      "gain & best gain 0.01660326340326357 , 0.04575952380952386\n",
      "size of data (78, 6)\n",
      "size of data (22, 6)\n",
      "gain & best gain 0.01660326340326357 , 0.04575952380952386\n",
      "size of data (79, 6)\n",
      "size of data (21, 6)\n",
      "gain & best gain 0.01720843881856582 , 0.04575952380952386\n",
      "size of data (81, 6)\n",
      "size of data (19, 6)\n",
      "gain & best gain 0.018534632878492663 , 0.04575952380952386\n",
      "size of data (81, 6)\n",
      "size of data (19, 6)\n",
      "gain & best gain 0.018534632878492663 , 0.04575952380952386\n",
      "size of data (82, 6)\n",
      "size of data (18, 6)\n",
      "gain & best gain 0.017183739837398626 , 0.04575952380952386\n",
      "size of data (83, 6)\n",
      "size of data (17, 6)\n",
      "gain & best gain 0.015163146704464947 , 0.04575952380952386\n",
      "size of data (84, 6)\n",
      "size of data (16, 6)\n",
      "gain & best gain 0.01748571428571455 , 0.04575952380952386\n",
      "size of data (86, 6)\n",
      "size of data (14, 6)\n",
      "gain & best gain 0.018183388704319126 , 0.04575952380952386\n",
      "size of data (86, 6)\n",
      "size of data (14, 6)\n",
      "gain & best gain 0.018183388704319126 , 0.04575952380952386\n",
      "size of data (87, 6)\n",
      "size of data (13, 6)\n",
      "gain & best gain 0.014694252873563407 , 0.04575952380952386\n",
      "size of data (88, 6)\n",
      "size of data (12, 6)\n",
      "gain & best gain 0.01236666666666697 , 0.04575952380952386\n",
      "size of data (89, 6)\n",
      "size of data (11, 6)\n",
      "gain & best gain 0.011453319713993992 , 0.04575952380952386\n",
      "size of data (90, 6)\n",
      "size of data (10, 6)\n",
      "gain & best gain 0.013866666666667027 , 0.04575952380952386\n",
      "size of data (91, 6)\n",
      "size of data (9, 6)\n",
      "gain & best gain 0.016362393162393407 , 0.04575952380952386\n",
      "size of data (94, 6)\n",
      "size of data (6, 6)\n",
      "gain & best gain 0.009228368794326647 , 0.04575952380952386\n",
      "size of data (94, 6)\n",
      "size of data (6, 6)\n",
      "gain & best gain 0.009228368794326647 , 0.04575952380952386\n",
      "size of data (94, 6)\n",
      "size of data (6, 6)\n",
      "gain & best gain 0.009228368794326647 , 0.04575952380952386\n",
      "size of data (96, 6)\n",
      "size of data (4, 6)\n",
      "gain & best gain 0.011116666666666997 , 0.04575952380952386\n",
      "size of data (96, 6)\n",
      "size of data (4, 6)\n",
      "gain & best gain 0.011116666666666997 , 0.04575952380952386\n",
      "size of data (97, 6)\n",
      "size of data (3, 6)\n",
      "gain & best gain 0.014402749140893678 , 0.04575952380952386\n",
      "size of data (99, 6)\n",
      "size of data (1, 6)\n",
      "gain & best gain 0.010270707070707319 , 0.04575952380952386\n",
      "size of data (99, 6)\n",
      "size of data (1, 6)\n",
      "gain & best gain 0.010270707070707319 , 0.04575952380952386\n",
      "feature id being considered: 27\n",
      "number of values to split: 99\n",
      "size of data (2, 6)\n",
      "size of data (98, 6)\n",
      "gain & best gain 0.019118367346938947 , 0.04575952380952386\n",
      "size of data (2, 6)\n",
      "size of data (98, 6)\n",
      "gain & best gain 0.019118367346938947 , 0.04575952380952386\n",
      "size of data (3, 6)\n",
      "size of data (97, 6)\n",
      "gain & best gain 0.015021305841924515 , 0.04575952380952386\n",
      "size of data (5, 6)\n",
      "size of data (95, 6)\n",
      "gain & best gain 0.013305263157894931 , 0.04575952380952386\n",
      "size of data (5, 6)\n",
      "size of data (95, 6)\n",
      "gain & best gain 0.013305263157894931 , 0.04575952380952386\n",
      "size of data (6, 6)\n",
      "size of data (94, 6)\n",
      "gain & best gain 0.014689361702127757 , 0.04575952380952386\n",
      "size of data (9, 6)\n",
      "size of data (91, 6)\n",
      "gain & best gain 0.010110866910867156 , 0.04575952380952386\n",
      "size of data (9, 6)\n",
      "size of data (91, 6)\n",
      "gain & best gain 0.010110866910867156 , 0.04575952380952386\n",
      "size of data (9, 6)\n",
      "size of data (91, 6)\n",
      "gain & best gain 0.010110866910867156 , 0.04575952380952386\n",
      "size of data (12, 6)\n",
      "size of data (88, 6)\n",
      "gain & best gain 0.01145757575757611 , 0.04575952380952386\n",
      "size of data (12, 6)\n",
      "size of data (88, 6)\n",
      "gain & best gain 0.01145757575757611 , 0.04575952380952386\n",
      "size of data (12, 6)\n",
      "size of data (88, 6)\n",
      "gain & best gain 0.01145757575757611 , 0.04575952380952386\n",
      "size of data (13, 6)\n",
      "size of data (87, 6)\n",
      "gain & best gain 0.013367992926613836 , 0.04575952380952386\n",
      "size of data (15, 6)\n",
      "size of data (85, 6)\n",
      "gain & best gain 0.01347450980392173 , 0.04575952380952386\n",
      "size of data (15, 6)\n",
      "size of data (85, 6)\n",
      "gain & best gain 0.01347450980392173 , 0.04575952380952386\n",
      "size of data (17, 6)\n",
      "size of data (83, 6)\n",
      "gain & best gain 0.020308433734939735 , 0.04575952380952386\n",
      "size of data (17, 6)\n",
      "size of data (83, 6)\n",
      "gain & best gain 0.020308433734939735 , 0.04575952380952386\n",
      "size of data (20, 6)\n",
      "size of data (80, 6)\n",
      "gain & best gain 0.018950000000000022 , 0.04575952380952386\n",
      "size of data (20, 6)\n",
      "size of data (80, 6)\n",
      "gain & best gain 0.018950000000000022 , 0.04575952380952386\n",
      "size of data (20, 6)\n",
      "size of data (80, 6)\n",
      "gain & best gain 0.018950000000000022 , 0.04575952380952386\n",
      "size of data (22, 6)\n",
      "size of data (78, 6)\n",
      "gain & best gain 0.015391142191142348 , 0.04575952380952386\n",
      "size of data (22, 6)\n",
      "size of data (78, 6)\n",
      "gain & best gain 0.015391142191142348 , 0.04575952380952386\n",
      "size of data (23, 6)\n",
      "size of data (77, 6)\n",
      "gain & best gain 0.014549520045172515 , 0.04575952380952386\n",
      "size of data (25, 6)\n",
      "size of data (75, 6)\n",
      "gain & best gain 0.015733333333333488 , 0.04575952380952386\n",
      "size of data (25, 6)\n",
      "size of data (75, 6)\n",
      "gain & best gain 0.015733333333333488 , 0.04575952380952386\n",
      "size of data (26, 6)\n",
      "size of data (74, 6)\n",
      "gain & best gain 0.01561164241164259 , 0.04575952380952386\n",
      "size of data (30, 6)\n",
      "size of data (70, 6)\n",
      "gain & best gain 0.014533333333333509 , 0.04575952380952386\n",
      "size of data (30, 6)\n",
      "size of data (70, 6)\n",
      "gain & best gain 0.014533333333333509 , 0.04575952380952386\n",
      "size of data (30, 6)\n",
      "size of data (70, 6)\n",
      "gain & best gain 0.014533333333333509 , 0.04575952380952386\n",
      "size of data (30, 6)\n",
      "size of data (70, 6)\n",
      "gain & best gain 0.014533333333333509 , 0.04575952380952386\n",
      "size of data (31, 6)\n",
      "size of data (69, 6)\n",
      "gain & best gain 0.011390743338008713 , 0.04575952380952386\n",
      "size of data (36, 6)\n",
      "size of data (64, 6)\n",
      "gain & best gain 0.017088888888889042 , 0.04575952380952386\n",
      "size of data (36, 6)\n",
      "size of data (64, 6)\n",
      "gain & best gain 0.017088888888889042 , 0.04575952380952386\n",
      "size of data (36, 6)\n",
      "size of data (64, 6)\n",
      "gain & best gain 0.017088888888889042 , 0.04575952380952386\n",
      "size of data (36, 6)\n",
      "size of data (64, 6)\n",
      "gain & best gain 0.017088888888889042 , 0.04575952380952386\n",
      "size of data (36, 6)\n",
      "size of data (64, 6)\n",
      "gain & best gain 0.017088888888889042 , 0.04575952380952386\n",
      "size of data (37, 6)\n",
      "size of data (63, 6)\n",
      "gain & best gain 0.014491291291291564 , 0.04575952380952386\n",
      "size of data (40, 6)\n",
      "size of data (60, 6)\n",
      "gain & best gain 0.01536666666666675 , 0.04575952380952386\n",
      "size of data (40, 6)\n",
      "size of data (60, 6)\n",
      "gain & best gain 0.01536666666666675 , 0.04575952380952386\n",
      "size of data (40, 6)\n",
      "size of data (60, 6)\n",
      "gain & best gain 0.01536666666666675 , 0.04575952380952386\n",
      "size of data (41, 6)\n",
      "size of data (59, 6)\n",
      "gain & best gain 0.013262009094667349 , 0.04575952380952386\n",
      "size of data (45, 6)\n",
      "size of data (55, 6)\n",
      "gain & best gain 0.017947474747475045 , 0.04575952380952386\n",
      "size of data (45, 6)\n",
      "size of data (55, 6)\n",
      "gain & best gain 0.017947474747475045 , 0.04575952380952386\n",
      "size of data (45, 6)\n",
      "size of data (55, 6)\n",
      "gain & best gain 0.017947474747475045 , 0.04575952380952386\n",
      "size of data (45, 6)\n",
      "size of data (55, 6)\n",
      "gain & best gain 0.017947474747475045 , 0.04575952380952386\n",
      "size of data (47, 6)\n",
      "size of data (53, 6)\n",
      "gain & best gain 0.013115696507426833 , 0.04575952380952386\n",
      "size of data (47, 6)\n",
      "size of data (53, 6)\n",
      "gain & best gain 0.013115696507426833 , 0.04575952380952386\n",
      "size of data (48, 6)\n",
      "size of data (52, 6)\n",
      "gain & best gain 0.01124487179487188 , 0.04575952380952386\n",
      "size of data (50, 6)\n",
      "size of data (50, 6)\n",
      "gain & best gain 0.009600000000000164 , 0.04575952380952386\n",
      "size of data (50, 6)\n",
      "size of data (50, 6)\n",
      "gain & best gain 0.009600000000000164 , 0.04575952380952386\n",
      "size of data (53, 6)\n",
      "size of data (47, 6)\n",
      "gain & best gain 0.011357366519470391 , 0.04575952380952386\n",
      "size of data (53, 6)\n",
      "size of data (47, 6)\n",
      "gain & best gain 0.011357366519470391 , 0.04575952380952386\n",
      "size of data (53, 6)\n",
      "size of data (47, 6)\n",
      "gain & best gain 0.011357366519470391 , 0.04575952380952386\n",
      "size of data (56, 6)\n",
      "size of data (44, 6)\n",
      "gain & best gain 0.010148051948052239 , 0.04575952380952386\n",
      "size of data (56, 6)\n",
      "size of data (44, 6)\n",
      "gain & best gain 0.010148051948052239 , 0.04575952380952386\n",
      "size of data (56, 6)\n",
      "size of data (44, 6)\n",
      "gain & best gain 0.010148051948052239 , 0.04575952380952386\n",
      "size of data (59, 6)\n",
      "size of data (41, 6)\n",
      "gain & best gain 0.014593137660190436 , 0.04575952380952386\n",
      "size of data (59, 6)\n",
      "size of data (41, 6)\n",
      "gain & best gain 0.014593137660190436 , 0.04575952380952386\n",
      "size of data (59, 6)\n",
      "size of data (41, 6)\n",
      "gain & best gain 0.014593137660190436 , 0.04575952380952386\n",
      "size of data (62, 6)\n",
      "size of data (38, 6)\n",
      "gain & best gain 0.01635789473684235 , 0.04575952380952386\n",
      "size of data (62, 6)\n",
      "size of data (38, 6)\n",
      "gain & best gain 0.01635789473684235 , 0.04575952380952386\n",
      "size of data (62, 6)\n",
      "size of data (38, 6)\n",
      "gain & best gain 0.01635789473684235 , 0.04575952380952386\n",
      "size of data (63, 6)\n",
      "size of data (37, 6)\n",
      "gain & best gain 0.018523895323895534 , 0.04575952380952386\n",
      "size of data (65, 6)\n",
      "size of data (35, 6)\n",
      "gain & best gain 0.018936263736264003 , 0.04575952380952386\n",
      "size of data (65, 6)\n",
      "size of data (35, 6)\n",
      "gain & best gain 0.018936263736264003 , 0.04575952380952386\n",
      "size of data (70, 6)\n",
      "size of data (30, 6)\n",
      "gain & best gain 0.024628571428571444 , 0.04575952380952386\n",
      "size of data (70, 6)\n",
      "size of data (30, 6)\n",
      "gain & best gain 0.024628571428571444 , 0.04575952380952386\n",
      "size of data (70, 6)\n",
      "size of data (30, 6)\n",
      "gain & best gain 0.024628571428571444 , 0.04575952380952386\n",
      "size of data (70, 6)\n",
      "size of data (30, 6)\n",
      "gain & best gain 0.024628571428571444 , 0.04575952380952386\n",
      "size of data (70, 6)\n",
      "size of data (30, 6)\n",
      "gain & best gain 0.024628571428571444 , 0.04575952380952386\n",
      "size of data (72, 6)\n",
      "size of data (28, 6)\n",
      "gain & best gain 0.02827936507936546 , 0.04575952380952386\n",
      "size of data (72, 6)\n",
      "size of data (28, 6)\n",
      "gain & best gain 0.02827936507936546 , 0.04575952380952386\n",
      "size of data (73, 6)\n",
      "size of data (27, 6)\n",
      "gain & best gain 0.02979563673262331 , 0.04575952380952386\n",
      "size of data (74, 6)\n",
      "size of data (26, 6)\n",
      "gain & best gain 0.031058627858628007 , 0.04575952380952386\n",
      "size of data (77, 6)\n",
      "size of data (23, 6)\n",
      "gain & best gain 0.01652580463015252 , 0.04575952380952386\n",
      "size of data (77, 6)\n",
      "size of data (23, 6)\n",
      "gain & best gain 0.01652580463015252 , 0.04575952380952386\n",
      "size of data (77, 6)\n",
      "size of data (23, 6)\n",
      "gain & best gain 0.01652580463015252 , 0.04575952380952386\n",
      "size of data (79, 6)\n",
      "size of data (21, 6)\n",
      "gain & best gain 0.01933019891500931 , 0.04575952380952386\n",
      "size of data (79, 6)\n",
      "size of data (21, 6)\n",
      "gain & best gain 0.01933019891500931 , 0.04575952380952386\n",
      "size of data (81, 6)\n",
      "size of data (19, 6)\n",
      "gain & best gain 0.02196543209876567 , 0.04575952380952386\n",
      "size of data (81, 6)\n",
      "size of data (19, 6)\n",
      "gain & best gain 0.02196543209876567 , 0.04575952380952386\n",
      "size of data (82, 6)\n",
      "size of data (18, 6)\n",
      "gain & best gain 0.017400542005420183 , 0.04575952380952386\n",
      "size of data (84, 6)\n",
      "size of data (16, 6)\n",
      "gain & best gain 0.0249857142857145 , 0.04575952380952386\n",
      "size of data (84, 6)\n",
      "size of data (16, 6)\n",
      "gain & best gain 0.0249857142857145 , 0.04575952380952386\n",
      "size of data (85, 6)\n",
      "size of data (15, 6)\n",
      "gain & best gain 0.020611764705882663 , 0.04575952380952386\n",
      "size of data (88, 6)\n",
      "size of data (12, 6)\n",
      "gain & best gain 0.023200000000000554 , 0.04575952380952386\n",
      "size of data (88, 6)\n",
      "size of data (12, 6)\n",
      "gain & best gain 0.023200000000000554 , 0.04575952380952386\n",
      "size of data (88, 6)\n",
      "size of data (12, 6)\n",
      "gain & best gain 0.023200000000000554 , 0.04575952380952386\n",
      "size of data (89, 6)\n",
      "size of data (11, 6)\n",
      "gain & best gain 0.02783738508682343 , 0.04575952380952386\n",
      "size of data (93, 6)\n",
      "size of data (7, 6)\n",
      "gain & best gain 0.012478033794163013 , 0.04575952380952386\n",
      "size of data (93, 6)\n",
      "size of data (7, 6)\n",
      "gain & best gain 0.012478033794163013 , 0.04575952380952386\n",
      "size of data (93, 6)\n",
      "size of data (7, 6)\n",
      "gain & best gain 0.012478033794163013 , 0.04575952380952386\n",
      "size of data (93, 6)\n",
      "size of data (7, 6)\n",
      "gain & best gain 0.012478033794163013 , 0.04575952380952386\n",
      "size of data (95, 6)\n",
      "size of data (5, 6)\n",
      "gain & best gain 0.017094736842105274 , 0.04575952380952386\n",
      "size of data (95, 6)\n",
      "size of data (5, 6)\n",
      "gain & best gain 0.017094736842105274 , 0.04575952380952386\n",
      "size of data (98, 6)\n",
      "size of data (2, 6)\n",
      "gain & best gain 0.008710204081632922 , 0.04575952380952386\n",
      "size of data (98, 6)\n",
      "size of data (2, 6)\n",
      "gain & best gain 0.008710204081632922 , 0.04575952380952386\n",
      "size of data (98, 6)\n",
      "size of data (2, 6)\n",
      "gain & best gain 0.008710204081632922 , 0.04575952380952386\n",
      "size of data (99, 6)\n",
      "size of data (1, 6)\n",
      "gain & best gain 0.009260606060606191 , 0.04575952380952386\n",
      "feature id being considered: 29\n",
      "number of values to split: 99\n",
      "size of data (2, 6)\n",
      "size of data (98, 6)\n",
      "gain & best gain 0.017485714285714327 , 0.04575952380952386\n",
      "size of data (2, 6)\n",
      "size of data (98, 6)\n",
      "gain & best gain 0.017485714285714327 , 0.04575952380952386\n",
      "size of data (3, 6)\n",
      "size of data (97, 6)\n",
      "gain & best gain 0.014815120274914273 , 0.04575952380952386\n",
      "size of data (4, 6)\n",
      "size of data (96, 6)\n",
      "gain & best gain 0.013408333333333577 , 0.04575952380952386\n",
      "size of data (6, 6)\n",
      "size of data (94, 6)\n",
      "gain & best gain 0.013696453900709504 , 0.04575952380952386\n",
      "size of data (6, 6)\n",
      "size of data (94, 6)\n",
      "gain & best gain 0.013696453900709504 , 0.04575952380952386\n",
      "size of data (8, 6)\n",
      "size of data (92, 6)\n",
      "gain & best gain 0.01091739130434799 , 0.04575952380952386\n",
      "size of data (8, 6)\n",
      "size of data (92, 6)\n",
      "gain & best gain 0.01091739130434799 , 0.04575952380952386\n",
      "size of data (11, 6)\n",
      "size of data (89, 6)\n",
      "gain & best gain 0.02456874361593475 , 0.04575952380952386\n",
      "size of data (11, 6)\n",
      "size of data (89, 6)\n",
      "gain & best gain 0.02456874361593475 , 0.04575952380952386\n",
      "size of data (11, 6)\n",
      "size of data (89, 6)\n",
      "gain & best gain 0.02456874361593475 , 0.04575952380952386\n",
      "size of data (12, 6)\n",
      "size of data (88, 6)\n",
      "gain & best gain 0.02092727272727324 , 0.04575952380952386\n",
      "size of data (13, 6)\n",
      "size of data (87, 6)\n",
      "gain & best gain 0.017063837312113472 , 0.04575952380952386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of data (15, 6)\n",
      "size of data (85, 6)\n",
      "gain & best gain 0.014650980392157287 , 0.04575952380952386\n",
      "size of data (15, 6)\n",
      "size of data (85, 6)\n",
      "gain & best gain 0.014650980392157287 , 0.04575952380952386\n",
      "size of data (16, 6)\n",
      "size of data (84, 6)\n",
      "gain & best gain 0.015759523809523834 , 0.04575952380952386\n",
      "size of data (18, 6)\n",
      "size of data (82, 6)\n",
      "gain & best gain 0.013687804878048992 , 0.04575952380952386\n",
      "size of data (18, 6)\n",
      "size of data (82, 6)\n",
      "gain & best gain 0.013687804878048992 , 0.04575952380952386\n",
      "size of data (19, 6)\n",
      "size of data (81, 6)\n",
      "gain & best gain 0.01177699805068233 , 0.04575952380952386\n",
      "size of data (20, 6)\n",
      "size of data (80, 6)\n",
      "gain & best gain 0.00945000000000007 , 0.04575952380952386\n",
      "size of data (22, 6)\n",
      "size of data (78, 6)\n",
      "gain & best gain 0.00963356643356672 , 0.04575952380952386\n",
      "size of data (22, 6)\n",
      "size of data (78, 6)\n",
      "gain & best gain 0.00963356643356672 , 0.04575952380952386\n",
      "size of data (24, 6)\n",
      "size of data (76, 6)\n",
      "gain & best gain 0.013507017543859856 , 0.04575952380952386\n",
      "size of data (24, 6)\n",
      "size of data (76, 6)\n",
      "gain & best gain 0.013507017543859856 , 0.04575952380952386\n",
      "size of data (26, 6)\n",
      "size of data (74, 6)\n",
      "gain & best gain 0.014052390852391072 , 0.04575952380952386\n",
      "size of data (26, 6)\n",
      "size of data (74, 6)\n",
      "gain & best gain 0.014052390852391072 , 0.04575952380952386\n",
      "size of data (27, 6)\n",
      "size of data (73, 6)\n",
      "gain & best gain 0.012910806697108423 , 0.04575952380952386\n",
      "size of data (28, 6)\n",
      "size of data (72, 6)\n",
      "gain & best gain 0.010819047619047617 , 0.04575952380952386\n",
      "size of data (29, 6)\n",
      "size of data (71, 6)\n",
      "gain & best gain 0.011417581350170236 , 0.04575952380952386\n",
      "size of data (30, 6)\n",
      "size of data (70, 6)\n",
      "gain & best gain 0.011104761904762173 , 0.04575952380952386\n",
      "size of data (32, 6)\n",
      "size of data (68, 6)\n",
      "gain & best gain 0.013126470588235684 , 0.04575952380952386\n",
      "size of data (32, 6)\n",
      "size of data (68, 6)\n",
      "gain & best gain 0.013126470588235684 , 0.04575952380952386\n",
      "size of data (33, 6)\n",
      "size of data (67, 6)\n",
      "gain & best gain 0.0114767978290371 , 0.04575952380952386\n",
      "size of data (36, 6)\n",
      "size of data (64, 6)\n",
      "gain & best gain 0.015491666666666903 , 0.04575952380952386\n",
      "size of data (36, 6)\n",
      "size of data (64, 6)\n",
      "gain & best gain 0.015491666666666903 , 0.04575952380952386\n",
      "size of data (36, 6)\n",
      "size of data (64, 6)\n",
      "gain & best gain 0.015491666666666903 , 0.04575952380952386\n",
      "size of data (37, 6)\n",
      "size of data (63, 6)\n",
      "gain & best gain 0.017236894036894324 , 0.04575952380952386\n",
      "size of data (38, 6)\n",
      "size of data (62, 6)\n",
      "gain & best gain 0.019838370118845594 , 0.04575952380952386\n",
      "size of data (39, 6)\n",
      "size of data (61, 6)\n",
      "gain & best gain 0.021056242118537405 , 0.04575952380952386\n",
      "size of data (41, 6)\n",
      "size of data (59, 6)\n",
      "gain & best gain 0.01575064076064525 , 0.04575952380952386\n",
      "size of data (41, 6)\n",
      "size of data (59, 6)\n",
      "gain & best gain 0.01575064076064525 , 0.04575952380952386\n",
      "size of data (42, 6)\n",
      "size of data (58, 6)\n",
      "gain & best gain 0.015860098522167854 , 0.04575952380952386\n",
      "size of data (43, 6)\n",
      "size of data (57, 6)\n",
      "gain & best gain 0.015782619339045345 , 0.04575952380952386\n",
      "size of data (45, 6)\n",
      "size of data (55, 6)\n",
      "gain & best gain 0.013058585858586103 , 0.04575952380952386\n",
      "size of data (45, 6)\n",
      "size of data (55, 6)\n",
      "gain & best gain 0.013058585858586103 , 0.04575952380952386\n",
      "size of data (48, 6)\n",
      "size of data (52, 6)\n",
      "gain & best gain 0.022398717948718172 , 0.04575952380952386\n",
      "size of data (48, 6)\n",
      "size of data (52, 6)\n",
      "gain & best gain 0.022398717948718172 , 0.04575952380952386\n",
      "size of data (48, 6)\n",
      "size of data (52, 6)\n",
      "gain & best gain 0.022398717948718172 , 0.04575952380952386\n",
      "size of data (49, 6)\n",
      "size of data (51, 6)\n",
      "gain & best gain 0.02685746298519409 , 0.04575952380952386\n",
      "size of data (50, 6)\n",
      "size of data (50, 6)\n",
      "gain & best gain 0.026799999999999935 , 0.04575952380952386\n",
      "size of data (51, 6)\n",
      "size of data (49, 6)\n",
      "gain & best gain 0.027481712685074156 , 0.04575952380952386\n",
      "size of data (52, 6)\n",
      "size of data (48, 6)\n",
      "gain & best gain 0.02579615384615408 , 0.04575952380952386\n",
      "size of data (54, 6)\n",
      "size of data (46, 6)\n",
      "gain & best gain 0.020188727858293176 , 0.04575952380952386\n",
      "size of data (54, 6)\n",
      "size of data (46, 6)\n",
      "gain & best gain 0.020188727858293176 , 0.04575952380952386\n",
      "size of data (58, 6)\n",
      "size of data (42, 6)\n",
      "gain & best gain 0.01674679802955703 , 0.04575952380952386\n",
      "size of data (58, 6)\n",
      "size of data (42, 6)\n",
      "gain & best gain 0.01674679802955703 , 0.04575952380952386\n",
      "size of data (58, 6)\n",
      "size of data (42, 6)\n",
      "gain & best gain 0.01674679802955703 , 0.04575952380952386\n",
      "size of data (58, 6)\n",
      "size of data (42, 6)\n",
      "gain & best gain 0.01674679802955703 , 0.04575952380952386\n",
      "size of data (59, 6)\n",
      "size of data (41, 6)\n",
      "gain & best gain 0.017652252997106377 , 0.04575952380952386\n",
      "size of data (61, 6)\n",
      "size of data (39, 6)\n",
      "gain & best gain 0.015928036990332517 , 0.04575952380952386\n",
      "size of data (61, 6)\n",
      "size of data (39, 6)\n",
      "gain & best gain 0.015928036990332517 , 0.04575952380952386\n",
      "size of data (63, 6)\n",
      "size of data (37, 6)\n",
      "gain & best gain 0.017425654225654563 , 0.04575952380952386\n",
      "size of data (63, 6)\n",
      "size of data (37, 6)\n",
      "gain & best gain 0.017425654225654563 , 0.04575952380952386\n",
      "size of data (65, 6)\n",
      "size of data (35, 6)\n",
      "gain & best gain 0.01304615384615404 , 0.04575952380952386\n",
      "size of data (65, 6)\n",
      "size of data (35, 6)\n",
      "gain & best gain 0.01304615384615404 , 0.04575952380952386\n",
      "size of data (67, 6)\n",
      "size of data (33, 6)\n",
      "gain & best gain 0.013837720488466987 , 0.04575952380952386\n",
      "size of data (67, 6)\n",
      "size of data (33, 6)\n",
      "gain & best gain 0.013837720488466987 , 0.04575952380952386\n",
      "size of data (68, 6)\n",
      "size of data (32, 6)\n",
      "gain & best gain 0.012133823529411947 , 0.04575952380952386\n",
      "size of data (69, 6)\n",
      "size of data (31, 6)\n",
      "gain & best gain 0.010493127629733756 , 0.04575952380952386\n",
      "size of data (70, 6)\n",
      "size of data (30, 6)\n",
      "gain & best gain 0.014057142857143212 , 0.04575952380952386\n",
      "size of data (71, 6)\n",
      "size of data (29, 6)\n",
      "gain & best gain 0.015264108790675524 , 0.04575952380952386\n",
      "size of data (73, 6)\n",
      "size of data (27, 6)\n",
      "gain & best gain 0.01367184170471858 , 0.04575952380952386\n",
      "size of data (73, 6)\n",
      "size of data (27, 6)\n",
      "gain & best gain 0.01367184170471858 , 0.04575952380952386\n",
      "size of data (75, 6)\n",
      "size of data (25, 6)\n",
      "gain & best gain 0.016533333333333622 , 0.04575952380952386\n",
      "size of data (75, 6)\n",
      "size of data (25, 6)\n",
      "gain & best gain 0.016533333333333622 , 0.04575952380952386\n",
      "size of data (77, 6)\n",
      "size of data (23, 6)\n",
      "gain & best gain 0.01810683229813681 , 0.04575952380952386\n",
      "size of data (77, 6)\n",
      "size of data (23, 6)\n",
      "gain & best gain 0.01810683229813681 , 0.04575952380952386\n",
      "size of data (78, 6)\n",
      "size of data (22, 6)\n",
      "gain & best gain 0.019144055944056215 , 0.04575952380952386\n",
      "size of data (79, 6)\n",
      "size of data (21, 6)\n",
      "gain & best gain 0.019101145268234032 , 0.04575952380952386\n",
      "size of data (80, 6)\n",
      "size of data (20, 6)\n",
      "gain & best gain 0.01595000000000013 , 0.04575952380952386\n",
      "size of data (81, 6)\n",
      "size of data (19, 6)\n",
      "gain & best gain 0.01814476933073428 , 0.04575952380952386\n",
      "size of data (83, 6)\n",
      "size of data (17, 6)\n",
      "gain & best gain 0.016183699503898197 , 0.04575952380952386\n",
      "size of data (83, 6)\n",
      "size of data (17, 6)\n",
      "gain & best gain 0.016183699503898197 , 0.04575952380952386\n",
      "size of data (86, 6)\n",
      "size of data (14, 6)\n",
      "gain & best gain 0.02300066445182758 , 0.04575952380952386\n",
      "size of data (86, 6)\n",
      "size of data (14, 6)\n",
      "gain & best gain 0.02300066445182758 , 0.04575952380952386\n",
      "size of data (86, 6)\n",
      "size of data (14, 6)\n",
      "gain & best gain 0.02300066445182758 , 0.04575952380952386\n",
      "size of data (88, 6)\n",
      "size of data (12, 6)\n",
      "gain & best gain 0.028806060606060835 , 0.04575952380952386\n",
      "size of data (88, 6)\n",
      "size of data (12, 6)\n",
      "gain & best gain 0.028806060606060835 , 0.04575952380952386\n",
      "size of data (89, 6)\n",
      "size of data (11, 6)\n",
      "gain & best gain 0.024303166496425166 , 0.04575952380952386\n",
      "size of data (90, 6)\n",
      "size of data (10, 6)\n",
      "gain & best gain 0.025422222222222235 , 0.04575952380952386\n",
      "size of data (91, 6)\n",
      "size of data (9, 6)\n",
      "gain & best gain 0.02740024420024445 , 0.04575952380952386\n",
      "size of data (93, 6)\n",
      "size of data (7, 6)\n",
      "gain & best gain 0.0302046082949311 , 0.04575952380952386\n",
      "size of data (93, 6)\n",
      "size of data (7, 6)\n",
      "gain & best gain 0.0302046082949311 , 0.04575952380952386\n",
      "size of data (96, 6)\n",
      "size of data (4, 6)\n",
      "gain & best gain 0.022575000000000345 , 0.04575952380952386\n",
      "size of data (96, 6)\n",
      "size of data (4, 6)\n",
      "gain & best gain 0.022575000000000345 , 0.04575952380952386\n",
      "size of data (96, 6)\n",
      "size of data (4, 6)\n",
      "gain & best gain 0.022575000000000345 , 0.04575952380952386\n",
      "size of data (99, 6)\n",
      "size of data (1, 6)\n",
      "gain & best gain 0.008654545454545581 , 0.04575952380952386\n",
      "size of data (99, 6)\n",
      "size of data (1, 6)\n",
      "gain & best gain 0.008654545454545581 , 0.04575952380952386\n",
      "size of data (99, 6)\n",
      "size of data (1, 6)\n",
      "gain & best gain 0.008654545454545581 , 0.04575952380952386\n",
      "best_gain > 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-3197f3028ca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mY1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-bf908e445379>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(x_train, y_train, m)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;31m#     x_train.append(y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mtrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-bf908e445379>\u001b[0m in \u001b[0;36mrandom_forest\u001b[0;34m(data_train, m)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfea_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfea_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuidTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfea_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-bf908e445379>\u001b[0m in \u001b[0;36mbuidTree\u001b[0;34m(data, fea_id)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbest_gain\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_gain > 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuidTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfea_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuidTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfea_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTreeNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "X1 = X_train[0:100, :]\n",
    "Y1 = Y_train[0:100]\n",
    "\n",
    "predict(X1,Y1, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def confusMax(Y_pred, Y_test):\n",
    "    num_class = len(np.unique(Y_test))\n",
    "#     print(np.unique(Y_test))\n",
    "    Y_hold = Y_test * num_class + Y_pred\n",
    "#     Y_hold = np.zeros(num_class * num_class)\n",
    "    Y_bin = np.arange(num_class * num_class + 1)\n",
    "    con_matrx = np.asarray(np.histogram(Y_hold, bins=Y_bin)[0]).reshape(num_class, num_class)\n",
    "#     return np.histogram(Y_hold, bins=Y_bin)\n",
    "    return con_matrx\n",
    "#     print(len(hold))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0, 795,   0,   0,   0,   0,  12,   0,   0,   0,   0],\n",
       "       [  0,   0, 747,   0,   0,   0,   0,   0,   0,   0,  11],\n",
       "       [  0,   0,   0, 726,   0,   4,   1,   0,   1,   0,   0],\n",
       "       [  0,   0,   0,   2, 721,   2,   0,   0,   0,   0,   0],\n",
       "       [  0,   1,   0,   5,   1, 712,   1,   0,   6,   0,   0],\n",
       "       [  1,  12,   0,   2,   0,   0, 711,   0,   1,   7,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 754,   0,   0,   0],\n",
       "       [  0,   2,   0,   1,   2,   7,   5,   0, 700,   0,   0],\n",
       "       [  0,   3,   0,   3,   0,   0,  22,   0,   0, 721,   0],\n",
       "       [  0,   0,  26,   0,   0,   0,   0,   0,   0,   0, 704]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y1 = KNN(X_train,X_test,Y_train,5)\n",
    "\n",
    "confusMax(Y1, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall(y_true,y_pred):\n",
    "    num_class = len(np.unique(Y_test))\n",
    "    print(num_class)\n",
    "    con_matrix = confusMax(y_pred,y_true)\n",
    "    sum_recall = 0.0\n",
    "    for j in range(num_class):\n",
    "        TP = 0\n",
    "        FN = 0\n",
    "        for i in range(num_class):\n",
    "            if(i == j):\n",
    "                TP += con_matrix[i][j]\n",
    "            else: \n",
    "                FN += con_matrix[i][j]\n",
    "        if TP == 0:\n",
    "            sum_recall += 0\n",
    "        else:             \n",
    "            sum_recall += (TP/(TP + FN))\n",
    "    recall = sum_recall/num_class\n",
    "    return recall\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "#      \"\"\"\n",
    "#     :type y_true: numpy.ndarray\n",
    "#     :type y_pred: numpy.ndarray\n",
    "#     :rtype: float\n",
    "#     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8921579871684698"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_class = len(np.unique(Y_test))\n",
    "\n",
    "Recall(Y_test, Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision(y_true,y_pred):\n",
    "    num_class = len(np.unique(Y_test))\n",
    "    con_matrix = confusMax(y_pred,y_true)\n",
    "#     num = len(con_matrix)\n",
    "#     print(num)\n",
    "    sum_prec = 0.0\n",
    "    for i in range(num_class):\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        for j in range(num_class):\n",
    "            if(i == j):\n",
    "                TP += con_matrix[i][j]\n",
    "            else: \n",
    "                FP += con_matrix[i][j]\n",
    "        if TP == 0:\n",
    "            sum_prec += 0\n",
    "        else:             \n",
    "            sum_prec += (TP/(TP + FP))\n",
    "        prec = sum_prec/num_class\n",
    "    return prec\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8917796237059065"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Precision(Y_test, Y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Predicitve_Analytics.py\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def Accuracy(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \n",
    "    \"\"\"\n",
    "    l = len(y_true)\n",
    "    count = 0\n",
    "    for i in range(l):\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            count = count + 1\n",
    "    acc = count/l\n",
    "    return acc\n",
    "\n",
    "def Recall(y_true,y_pred):\n",
    "     \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "\n",
    "def Precision(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "def WCSS(Clusters):\n",
    "    \"\"\"\n",
    "    :Clusters List[numpy.ndarray]\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    \n",
    "def ConfusionMatrix(y_true,y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\"  \n",
    "\n",
    "def KNN(X_train,X_test,Y_train,N):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    :typr N: constant\n",
    "    \n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    cos_sim = KNN_find_similarity(X_train, X_test)\n",
    "    Y_pred = KNN_predict(cos_sim,N,Y_train)\n",
    "    \n",
    "    return Y_pred\n",
    "        \n",
    "def RandomForest(X_train,Y_train,X_test):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "def PCA(X_train,N):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type N: int\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    # compute mean of feature vectors\n",
    "    mean_vector = np.mean(X_train,axis = 0)\n",
    "\n",
    "    # compute covariance matrix of X_train\n",
    "    covMat=np.cov(X_train,rowvar=0)\n",
    "\n",
    "    # compute eigen values and eigen vectors of the covariance matrix\n",
    "    eigen_values,eigen_vectors=np.linalg.eig(np.mat(covMat))\n",
    "    #print(eigen_vectors.shape)\n",
    "\n",
    "    # sort eigen values\n",
    "    #print(eigen_values)\n",
    "    #print(np.sort(eigen_values))\n",
    "    increased_sort_ind = np.argsort(eigen_values)\n",
    "    #print(increased_sort_ind)\n",
    "\n",
    "    # get maximum N values' index\n",
    "    index_Nmax = increased_sort_ind[-1:-(N+1):-1]\n",
    "\n",
    "\n",
    "    #get maximum N eigen vectors\n",
    "    n_eigen_vectors=eigen_vectors[:,index_Nmax] \n",
    "    #print(n_eigen_vectors.shape)\n",
    "\n",
    "    # compute new n*N data matrix\n",
    "    new_data = np.dot(X_train,n_eigen_vectors)\n",
    "\n",
    "    #print(new_data.shape)\n",
    "    return new_data\n",
    "    \n",
    "def Kmeans(X_train,N):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type N: int\n",
    "    :rtype: List[numpy.ndarray]\n",
    "    \"\"\"\n",
    "    centroids = find_centroids(X_train,N)\n",
    "    return centroids\n",
    "\n",
    "def SklearnSupervisedLearning(X_train,Y_train,X_test):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: List[numpy.ndarray] \n",
    "    \"\"\"\n",
    "\n",
    "def SklearnVotingClassifier(X_train,Y_train,X_test):\n",
    "    \n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: List[numpy.ndarray] \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "#\"\"\"\n",
    "#Create your own custom functions for Matplotlib visualization of hyperparameter search. \n",
    "#Make sure that plots are labeled and proper legends are used\n",
    "#\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time of KNN 33.30502200126648 .\n",
      "Accuracy of KNN 0.9841289219875473 .\n",
      "============================\n",
      "10000\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> (11, 48)\n",
      "9999\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> (11, 48)\n",
      "Runtime of K-Means:  0.1835639476776123 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuxuanzhang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    }
   ],
   "source": [
    "len_train = len(Y_train)\n",
    "len_test = len(Y_test)\n",
    "\n",
    "## KNN\n",
    "K_knn = 11\n",
    "\n",
    "s1 = time.time()\n",
    "Y_pred_knn = KNN(X_train,X_test,Y_train,K_knn)\n",
    "e1 = time.time()\n",
    "\n",
    "#Y_pred_knn = np.asarray(Y_pred_knn)\n",
    "#print(Y_pred_knn.shape)\n",
    "#print(Y_test.shape)\n",
    "#acc_knn = Accuracy(Y_test, Y_pred_knn)\n",
    "#print(acc_knn)\n",
    "acc_knn = Accuracy(Y_test,Y_pred_knn)\n",
    "\n",
    "print(\"Running time of KNN\",e1-s1,\".\")\n",
    "print(\"Accuracy of KNN\",acc_knn,\".\")\n",
    "print(\"============================\")\n",
    "\n",
    "## K-Means\n",
    "K_kmeans = 11\n",
    "\n",
    "s2 = time.time()\n",
    "centroids = Kmeans(X_train,K_kmeans)\n",
    "e2 = time.time()\n",
    "print(\"Runtime of K-Means: \",e2-s2,\"s.\")\n",
    "#print(centroids)\n",
    "\n",
    "## PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [np.array([1,2,3,4])]*5\n",
    "print(a)\n",
    "b = np.asarray(a)\n",
    "print(b)\n",
    "print(b.shape)\n",
    "aa = np.sum(np.square(a),axis = 1)\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.zeros((3,2))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n",
      "[[0. 0. 0. 0.]\n",
      " [1. 2. 3. 4.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4],[2,3,4,5],[3,4,5,6],[4,5,6,7],[5,6,7,8]])\n",
    "print(a.shape)\n",
    "x = np.zeros((6,4))\n",
    "x[1,:] = a[0]\n",
    "print(x)\n",
    "\n",
    "\n",
    "#print(a[:,0])\n",
    "#print(a.max(axis=0))\n",
    "b = a.argmax(axis=0)\n",
    "#print(b[0])\n",
    "\n",
    "aaa = []*11\n",
    "aaa.append([1,2,3])\n",
    "aaa.append([222])\n",
    "aaa.append([3,2,1])\n",
    "#print(aaa[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.96222509e-01 5.46346345e-01 6.46898682e-01 8.38899954e-01\n",
      "  7.27504165e-01 7.83784611e-01 5.29478346e-01 5.29326875e-01\n",
      "  5.28742346e-01 5.47212657e-01 5.47290494e-01 5.47474042e-01\n",
      "  1.58367340e-02 2.03587274e-02 6.42754199e-02 1.57654043e-02\n",
      "  3.56626558e-02 4.78043144e-02 5.32182908e-01 5.32177568e-01\n",
      "  5.32247871e-01 5.33635662e-01 5.33666652e-01 5.33752106e-01\n",
      "  5.41685345e-01 5.62270157e-01 4.52617717e-01 5.43255924e-01\n",
      "  5.14683908e-01 5.86250793e-01 3.22484271e-01 3.37697482e-01\n",
      "  3.28006638e-01 1.94725347e-01 1.97781648e-01 2.00199773e-01\n",
      "  5.70687900e-04 3.75546138e-02 6.60251842e-02 3.49249768e-04\n",
      "  4.87408056e-02 7.45192054e-02 3.72725076e-01 4.23218629e-01\n",
      "  4.32447952e-01 3.24090481e-01 3.52505404e-01 3.16465685e-01\n",
      "  2.00000000e+00]\n",
      " [5.96065939e-01 5.43367815e-01 6.41493724e-01 8.38773637e-01\n",
      "  7.16552764e-01 7.81160565e-01 7.01563656e-01 7.01586333e-01\n",
      "  7.01451618e-01 5.42056622e-01 5.42226998e-01 5.42502400e-01\n",
      "  1.67388036e-02 2.00252471e-02 6.43814050e-02 1.64291404e-02\n",
      "  3.73373500e-02 5.26771622e-02 5.78156411e-01 5.78153134e-01\n",
      "  5.78245306e-01 5.78768468e-01 5.78802070e-01 5.78885373e-01\n",
      "  5.42500802e-01 5.53808230e-01 4.51919228e-01 5.43988611e-01\n",
      "  5.06457971e-01 5.86665807e-01 3.19023512e-01 3.34385360e-01\n",
      "  3.24740858e-01 1.97015664e-01 2.00197917e-01 2.02595651e-01\n",
      "  2.40780993e-04 3.55199979e-02 6.45403286e-02 2.08563800e-04\n",
      "  4.55265605e-02 7.50641142e-02 3.61802082e-01 4.11284355e-01\n",
      "  4.18886633e-01 3.30090061e-01 3.58567327e-01 3.22426329e-01\n",
      "  9.00000000e+00]\n",
      " [5.96424254e-01 5.46046914e-01 6.47118393e-01 8.39214997e-01\n",
      "  7.27894088e-01 7.85873381e-01 7.24488513e-01 7.24381265e-01\n",
      "  7.24007559e-01 5.63341663e-01 5.63423172e-01 5.63536417e-01\n",
      "  1.59172146e-02 1.95576853e-02 5.83981586e-02 1.57572273e-02\n",
      "  3.56469888e-02 4.93897960e-02 5.33742477e-01 5.33737032e-01\n",
      "  5.33825076e-01 5.34557139e-01 5.34590365e-01 5.34667818e-01\n",
      "  5.41576022e-01 5.60536745e-01 4.53559774e-01 5.43292448e-01\n",
      "  5.13733190e-01 5.89388775e-01 2.97476771e-01 3.12581630e-01\n",
      "  3.04100314e-01 2.09371398e-01 2.12705144e-01 2.15468351e-01\n",
      "  2.04538575e-04 3.35860419e-02 6.48551836e-02 2.06533906e-04\n",
      "  4.63107494e-02 7.30324541e-02 3.71907763e-01 4.22361143e-01\n",
      "  4.31167107e-01 3.17144998e-01 3.45522388e-01 3.09779744e-01\n",
      "  6.00000000e+00]\n",
      " [5.95654593e-01 5.43311078e-01 6.44436169e-01 8.39087478e-01\n",
      "  7.17685593e-01 7.80774379e-01 2.19330693e-01 2.19283543e-01\n",
      "  2.18463564e-01 1.15283898e-01 1.15257929e-01 1.15447206e-01\n",
      "  1.58362418e-02 1.94415774e-02 5.84935626e-02 1.58234568e-02\n",
      "  3.57475320e-02 4.91952530e-02 5.48196255e-01 5.48193347e-01\n",
      "  5.48284785e-01 5.49736896e-01 5.49768076e-01 5.49862337e-01\n",
      "  5.42705533e-01 5.52307352e-01 4.52459827e-01 5.44032303e-01\n",
      "  5.07423812e-01 5.88723316e-01 2.95638776e-01 3.10868400e-01\n",
      "  3.02249670e-01 1.65876757e-01 1.68434128e-01 1.70109678e-01\n",
      "  2.38455194e-04 3.48545863e-02 6.39812581e-02 2.22929410e-04\n",
      "  4.81427579e-02 7.62567994e-02 3.86064616e-01 4.38018043e-01\n",
      "  4.48862183e-01 3.27717437e-01 3.56153432e-01 3.19782129e-01\n",
      "  1.10000000e+01]\n",
      " [5.96358047e-01 5.43156109e-01 6.43222576e-01 8.39022871e-01\n",
      "  7.16240783e-01 7.81179697e-01 7.41172041e-01 7.41211280e-01\n",
      "  7.41039976e-01 7.25251968e-01 7.25505103e-01 7.25822529e-01\n",
      "  1.25409251e-02 1.52174755e-02 4.46524183e-02 1.25623614e-02\n",
      "  2.76515446e-02 3.70060808e-02 3.28606659e-01 3.28598851e-01\n",
      "  3.28595846e-01 3.29565143e-01 3.29580593e-01 3.29576969e-01\n",
      "  5.42392332e-01 5.53114103e-01 4.51705567e-01 5.43930599e-01\n",
      "  5.04208308e-01 5.86144763e-01 3.26606807e-01 3.42089240e-01\n",
      "  3.32243318e-01 2.30585723e-01 2.34465682e-01 2.37673338e-01\n",
      "  1.91498968e-04 3.00108451e-02 5.91048276e-02 1.74884183e-04\n",
      "  4.03672198e-02 6.74233907e-02 3.71025992e-01 4.21229478e-01\n",
      "  4.29770232e-01 3.27562256e-01 3.55974752e-01 3.19881046e-01\n",
      "  4.49866429e+00]\n",
      " [5.96242946e-01 5.46330788e-01 6.49257066e-01 8.39181025e-01\n",
      "  7.28284135e-01 7.84683276e-01 5.05478102e-01 5.05323808e-01\n",
      "  5.04601093e-01 5.83937282e-01 5.84024452e-01 5.84184648e-01\n",
      "  1.58136966e-02 1.92813247e-02 6.14478609e-02 1.55616672e-02\n",
      "  3.55251941e-02 4.87247419e-02 5.07949718e-01 5.07946165e-01\n",
      "  5.08000422e-01 5.08177594e-01 5.08205597e-01 5.08264547e-01\n",
      "  5.41726054e-01 5.61620177e-01 4.53933217e-01 5.43330760e-01\n",
      "  5.14510290e-01 5.89121647e-01 2.97391329e-01 3.12457533e-01\n",
      "  3.04015666e-01 2.15865432e-01 2.19317572e-01 2.22222191e-01\n",
      "  2.11473248e-04 3.12372478e-02 6.35648186e-02 2.08116288e-04\n",
      "  4.35256405e-02 7.18314009e-02 3.62445208e-01 4.11926508e-01\n",
      "  4.19686207e-01 3.27450949e-01 3.55916944e-01 3.19833430e-01\n",
      "  1.00000000e+01]\n",
      " [5.96119369e-01 5.43379281e-01 6.41935046e-01 8.38882768e-01\n",
      "  7.17156734e-01 7.80243159e-01 8.07476417e-01 8.07514530e-01\n",
      "  8.07479066e-01 6.75229167e-01 6.75452532e-01 6.75791533e-01\n",
      "  1.66186292e-02 1.98105618e-02 6.23477869e-02 1.64926535e-02\n",
      "  3.63960387e-02 5.00455240e-02 5.60347212e-01 5.60344744e-01\n",
      "  5.60435575e-01 5.60399978e-01 5.60435321e-01 5.60524090e-01\n",
      "  5.42351069e-01 5.54300942e-01 4.53026456e-01 5.43919396e-01\n",
      "  5.06258315e-01 5.86633744e-01 3.16862086e-01 3.32178880e-01\n",
      "  3.22717697e-01 2.21602549e-01 2.25265157e-01 2.28244545e-01\n",
      "  2.35304825e-04 3.18236430e-02 6.32063220e-02 2.11796214e-04\n",
      "  4.58531237e-02 7.31377340e-02 3.70784302e-01 4.21143961e-01\n",
      "  4.29770570e-01 3.26802946e-01 3.55318651e-01 3.19172975e-01\n",
      "  8.00000000e+00]\n",
      " [5.96574123e-01 5.46249215e-01 6.46831288e-01 8.39063621e-01\n",
      "  7.27625065e-01 7.84116986e-01 8.74272241e-01 8.74177404e-01\n",
      "  8.73987030e-01 9.23348286e-01 9.23589750e-01 9.23849072e-01\n",
      "  1.52246977e-02 1.87250440e-02 5.41573844e-02 1.51149256e-02\n",
      "  3.38608862e-02 4.59784876e-02 4.62492978e-01 4.62488052e-01\n",
      "  4.62538727e-01 4.62423128e-01 4.62446136e-01 4.62489108e-01\n",
      "  5.41529376e-01 5.60870263e-01 4.56209073e-01 5.43279248e-01\n",
      "  5.12631252e-01 5.87790851e-01 3.22707581e-01 3.37939987e-01\n",
      "  3.28297630e-01 2.59967465e-01 2.64298890e-01 2.68264602e-01\n",
      "  2.14527881e-04 2.96534727e-02 6.30522330e-02 2.09518009e-04\n",
      "  4.25955067e-02 7.18102371e-02 3.70417197e-01 4.20708709e-01\n",
      "  4.29192736e-01 3.18347522e-01 3.46620800e-01 3.10688435e-01\n",
      "  7.00000000e+00]\n",
      " [5.96098744e-01 5.43424505e-01 6.41274091e-01 8.38401209e-01\n",
      "  7.16300892e-01 7.79524338e-01 7.69291316e-01 7.69321376e-01\n",
      "  7.69273702e-01 7.41364988e-01 7.41624673e-01 7.42004592e-01\n",
      "  2.03481028e-02 2.53435348e-02 7.68515762e-02 1.99995939e-02\n",
      "  4.54781874e-02 6.23386234e-02 7.78459919e-01 7.78455033e-01\n",
      "  7.78631972e-01 7.79428668e-01 7.79479294e-01 7.79657633e-01\n",
      "  5.42547135e-01 5.54993596e-01 4.53183835e-01 5.44202590e-01\n",
      "  5.06021746e-01 5.87211927e-01 3.41260030e-01 3.56713741e-01\n",
      "  3.46149760e-01 2.09365396e-01 2.12773959e-01 2.15485313e-01\n",
      "  5.32084378e-04 3.96980392e-02 6.68737176e-02 3.20582726e-04\n",
      "  5.04758516e-02 8.01265195e-02 3.53149680e-01 4.01674053e-01\n",
      "  4.07884581e-01 3.30907849e-01 3.59488344e-01 3.23046592e-01\n",
      "  4.50133333e+00]\n",
      " [5.96351017e-01 5.46063794e-01 6.48507686e-01 8.39068896e-01\n",
      "  7.28621980e-01 7.84535751e-01 7.71378099e-01 7.71277071e-01\n",
      "  7.70891184e-01 5.38295635e-01 5.38359949e-01 5.38514769e-01\n",
      "  1.58084926e-02 1.95510672e-02 6.05134751e-02 1.53602545e-02\n",
      "  3.43553570e-02 4.88055646e-02 4.84156941e-01 4.84145819e-01\n",
      "  4.84187214e-01 4.85705594e-01 4.85731470e-01 4.85772994e-01\n",
      "  5.41471145e-01 5.60921805e-01 4.55630779e-01 5.43310255e-01\n",
      "  5.15339407e-01 5.87587555e-01 3.20418993e-01 3.35660144e-01\n",
      "  3.26101935e-01 2.16736318e-01 2.20192444e-01 2.23147398e-01\n",
      "  2.10254520e-04 3.49595808e-02 6.15252585e-02 2.02499758e-04\n",
      "  4.17966610e-02 7.12451642e-02 3.51670659e-01 3.99883764e-01\n",
      "  4.06119168e-01 3.31976255e-01 3.60452024e-01 3.24418858e-01\n",
      "  1.00000000e+00]\n",
      " [5.96351305e-01 5.46355295e-01 6.47500219e-01 8.39071659e-01\n",
      "  7.28290394e-01 7.84812768e-01 6.91381700e-01 6.91254091e-01\n",
      "  6.90824880e-01 6.66814506e-01 6.66937835e-01 6.67112847e-01\n",
      "  1.49792230e-02 1.86667868e-02 5.85593001e-02 1.46762201e-02\n",
      "  3.27874432e-02 4.47713737e-02 4.54467170e-01 4.54457705e-01\n",
      "  4.54482952e-01 4.55277257e-01 4.55302127e-01 4.55342710e-01\n",
      "  5.41573989e-01 5.61452307e-01 4.54041041e-01 5.43303751e-01\n",
      "  5.13892027e-01 5.89203909e-01 3.23357248e-01 3.38584881e-01\n",
      "  3.28869464e-01 2.21002307e-01 2.24550090e-01 2.27561983e-01\n",
      "  2.01452544e-04 3.32349524e-02 6.03985237e-02 2.10348392e-04\n",
      "  4.31603815e-02 7.21392774e-02 3.65730505e-01 4.15446140e-01\n",
      "  4.23708576e-01 3.24808685e-01 3.53201750e-01 3.17082751e-01\n",
      "  3.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "    \n",
    "kmeans = KMeans(n_clusters=11).fit(train_df)\n",
    "centroids = kmeans.cluster_centers_\n",
    "print(centroids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(X_train,Y_train)\n",
    "a = Accuracy(Y_test,knn.predict(X_test))\n",
    "print(a,\"==========11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
