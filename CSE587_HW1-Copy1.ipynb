{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "from math import log\n",
    "\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32765, 48) (32765,)\n",
      "size of training data: 32765\n",
      "size of testing data: 8191\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv('./data.csv')\n",
    "\n",
    "data_size = dataframe.shape[0]\n",
    "feature_num = dataframe.shape[1] - 1\n",
    "test_size = round(data_size * 0.2)\n",
    "#print(test_size)\n",
    "\n",
    "# normalization\n",
    "df = dataframe.iloc[:, 0:48]\n",
    "xmax = df.max()\n",
    "xmin = df.min()\n",
    "\n",
    "dff=(df-xmin)/(xmax-xmin)\n",
    "#print(dff)\n",
    "\n",
    "dataframee = pd.concat([dff,dataframe['48']],axis=1)\n",
    "\n",
    "#Split data\n",
    "random.seed(0)\n",
    "indices = dataframee.index.tolist()\n",
    "#print(indices)\n",
    "test_in = random.sample(population = indices, k = test_size)\n",
    "#print(test_in)\n",
    "\n",
    "test_df = dataframee.loc[test_in]\n",
    "train_df = dataframee.drop(test_in)\n",
    "\n",
    "\n",
    "\n",
    "X_train_df = (train_df.iloc[:, 0:48])\n",
    "Y_train_df = train_df['48']\n",
    "\n",
    "X_test_df = (test_df.iloc[:, 0:48])\n",
    "Y_test_df = test_df['48'] \n",
    "\n",
    "X_train = X_train_df.to_numpy()\n",
    "Y_train = Y_train_df.to_numpy()\n",
    "X_test = X_test_df.to_numpy()\n",
    "Y_test = Y_test_df.to_numpy()\n",
    "\n",
    "print(X_train.shape,Y_train.shape)\n",
    "    \n",
    "print(\"size of training data:\",len(X_train))\n",
    "print(\"size of testing data:\", len(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.596225</td>\n",
       "      <td>0.540284</td>\n",
       "      <td>0.615606</td>\n",
       "      <td>0.838338</td>\n",
       "      <td>0.717266</td>\n",
       "      <td>0.773620</td>\n",
       "      <td>0.710818</td>\n",
       "      <td>0.710995</td>\n",
       "      <td>0.712087</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.012935</td>\n",
       "      <td>0.110421</td>\n",
       "      <td>0.320896</td>\n",
       "      <td>0.364686</td>\n",
       "      <td>0.358736</td>\n",
       "      <td>0.317241</td>\n",
       "      <td>0.344491</td>\n",
       "      <td>0.308625</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.596119</td>\n",
       "      <td>0.541987</td>\n",
       "      <td>0.657480</td>\n",
       "      <td>0.839107</td>\n",
       "      <td>0.714800</td>\n",
       "      <td>0.756745</td>\n",
       "      <td>0.784912</td>\n",
       "      <td>0.785015</td>\n",
       "      <td>0.784224</td>\n",
       "      <td>0.710168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.015774</td>\n",
       "      <td>0.058570</td>\n",
       "      <td>0.464179</td>\n",
       "      <td>0.524752</td>\n",
       "      <td>0.552045</td>\n",
       "      <td>0.228966</td>\n",
       "      <td>0.256625</td>\n",
       "      <td>0.221024</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.596369</td>\n",
       "      <td>0.544879</td>\n",
       "      <td>0.644498</td>\n",
       "      <td>0.839618</td>\n",
       "      <td>0.724341</td>\n",
       "      <td>0.781678</td>\n",
       "      <td>0.688424</td>\n",
       "      <td>0.688369</td>\n",
       "      <td>0.688078</td>\n",
       "      <td>0.533995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.038273</td>\n",
       "      <td>0.148641</td>\n",
       "      <td>0.383582</td>\n",
       "      <td>0.435644</td>\n",
       "      <td>0.444238</td>\n",
       "      <td>0.329655</td>\n",
       "      <td>0.358438</td>\n",
       "      <td>0.320755</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.596565</td>\n",
       "      <td>0.543414</td>\n",
       "      <td>0.630369</td>\n",
       "      <td>0.838824</td>\n",
       "      <td>0.702555</td>\n",
       "      <td>0.798007</td>\n",
       "      <td>0.700639</td>\n",
       "      <td>0.700660</td>\n",
       "      <td>0.701047</td>\n",
       "      <td>0.516568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.006927</td>\n",
       "      <td>0.048715</td>\n",
       "      <td>0.326866</td>\n",
       "      <td>0.372937</td>\n",
       "      <td>0.379182</td>\n",
       "      <td>0.371034</td>\n",
       "      <td>0.400279</td>\n",
       "      <td>0.362534</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.596308</td>\n",
       "      <td>0.545396</td>\n",
       "      <td>0.646339</td>\n",
       "      <td>0.838603</td>\n",
       "      <td>0.722751</td>\n",
       "      <td>0.783740</td>\n",
       "      <td>0.764063</td>\n",
       "      <td>0.763992</td>\n",
       "      <td>0.763704</td>\n",
       "      <td>0.582751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.028285</td>\n",
       "      <td>0.112182</td>\n",
       "      <td>0.391045</td>\n",
       "      <td>0.443894</td>\n",
       "      <td>0.453532</td>\n",
       "      <td>0.325517</td>\n",
       "      <td>0.354254</td>\n",
       "      <td>0.316712</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.596225  0.540284  0.615606  0.838338  0.717266  0.773620  0.710818   \n",
       "1  0.596119  0.541987  0.657480  0.839107  0.714800  0.756745  0.784912   \n",
       "2  0.596369  0.544879  0.644498  0.839618  0.724341  0.781678  0.688424   \n",
       "3  0.596565  0.543414  0.630369  0.838824  0.702555  0.798007  0.700639   \n",
       "4  0.596308  0.545396  0.646339  0.838603  0.722751  0.783740  0.764063   \n",
       "\n",
       "          7         8         9  ...        39        40        41        42  \\\n",
       "0  0.710995  0.712087  0.644000  ...  0.000151  0.012935  0.110421  0.320896   \n",
       "1  0.785015  0.784224  0.710168  ...  0.000240  0.015774  0.058570  0.464179   \n",
       "2  0.688369  0.688078  0.533995  ...  0.000351  0.038273  0.148641  0.383582   \n",
       "3  0.700660  0.701047  0.516568  ...  0.000167  0.006927  0.048715  0.326866   \n",
       "4  0.763992  0.763704  0.582751  ...  0.000350  0.028285  0.112182  0.391045   \n",
       "\n",
       "         43        44        45        46        47  48  \n",
       "0  0.364686  0.358736  0.317241  0.344491  0.308625   5  \n",
       "1  0.524752  0.552045  0.228966  0.256625  0.221024   8  \n",
       "2  0.435644  0.444238  0.329655  0.358438  0.320755   9  \n",
       "3  0.372937  0.379182  0.371034  0.400279  0.362534   9  \n",
       "4  0.443894  0.453532  0.325517  0.354254  0.316712   6  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframee.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_find_similarity(X_train, X_test):\n",
    "    norm_test = np.linalg.norm(X_test, axis = 1)\n",
    "    norm_test = np.reshape(norm_test,(-1,1))\n",
    "    norm_train = np.linalg.norm((X_train), axis = 1)\n",
    "    norm_train = np.reshape(norm_train,(1,-1))\n",
    "    \n",
    "    norm = np.dot(norm_test,norm_train) \n",
    "    cos_sim = np.dot(X_test, np.transpose(X_train))/norm\n",
    "    \n",
    "    return cos_sim\n",
    "\n",
    "def KNN_predict(cos_sim,K,Y_train):\n",
    "    Y_pred = []\n",
    "    for row in cos_sim:\n",
    "        votes=[]\n",
    "        index = row.argsort()[::-1][0:K]\n",
    "        for i in index:\n",
    "            votes.append(Y_train[i])\n",
    "        mmax = np.argmax(np.bincount(votes))\n",
    "        Y_pred.append(mmax)\n",
    "    Y_pred = np.asarray(Y_pred)\n",
    "    return Y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find k cluster center\n",
    "#use test set to find which cluster center it similar to \n",
    "def update_centroids(centers, X_train):\n",
    "    #k = len(centers)\n",
    "    k = centers.shape[0]\n",
    "    n = X_train.shape[0]\n",
    "    d = X_train.shape[1]\n",
    "    \n",
    "    #centers = np.asarray(centers)\n",
    "    #print(centers.shape)\n",
    "    #print(X_train.shape)\n",
    "    #print(\"AAAAAAAAAAAAAAAAAAAA\")\n",
    "    \n",
    "    #compute l2\n",
    "    aa = np.sum(np.square(centers),axis = 1)\n",
    "    bb = np.sum(np.square(X_train),axis = 1)\n",
    "    #print(aa.shape)\n",
    "    #print(bb.shape)\n",
    "    aa = np.reshape(aa,(-1,1))\n",
    "    bb = np.reshape(bb,(-1,1))\n",
    "    #print(aa.shape)\n",
    "    #print(bb.shape)\n",
    "    aa = np.tile(aa,n)\n",
    "    bb = np.tile(bb,k)\n",
    "    bb = np.transpose(bb)\n",
    "    \n",
    "    cc = -2 * np.dot(centers,np.transpose(X_train))\n",
    "    #print(aa.shape)\n",
    "    #print(bb.shape)\n",
    "    #print(cc.shape)\n",
    "    #print(\"BBBBBBBBBBBBBBBBBBBBBB\")\n",
    "    xx = aa + bb + cc\n",
    "    #print(\"bbbbbbbbbbbbbbbbbbbbbbbb\")\n",
    "    dist = np.sqrt(xx)\n",
    "    #print(\"bbbbbbbbbbccccccccccccccc\")\n",
    "    colmax = dist.argmax(axis=0)\n",
    "    #print(\"CCCCCCCCCCCCCCCCCCCCCCCC\")\n",
    "    \n",
    "    \n",
    "    #new_centers = [np.zeros(d)] * k\n",
    "    #new_centers = np.asarray(new_centers)\n",
    "    \n",
    "    #print(\"new_centers\",new_centers.shape)\n",
    "    \n",
    "    new_centers = np.zeros((k,d))\n",
    "    \n",
    "    clusters = [np.zeros((n,d))] * k\n",
    "    \n",
    "    \n",
    "    for i in range(n):\n",
    "        cluster_i = colmax[i]\n",
    "        #clusters[cluster_i].append(X_train[i])\n",
    "        clusters[cluster_i][i,:]=X_train[i]\n",
    "    #print(\"DDDDDDDDDDDDDDDDDDDDD\")\n",
    "    \n",
    "    \n",
    "    #clusters = np.asarray(clusters)\n",
    "    for j in range(k):\n",
    "        new_centers[j] = np.mean(clusters[j],axis=0)\n",
    "    #print(\"EEEEEEEEEEEEEEEEEEEEEEEEE\")\n",
    "    #print(type(new_centers))\n",
    "    \n",
    "    return new_centers  # k * d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroids(X_train,K):\n",
    "    d = X_train.shape[1]\n",
    "    \n",
    "    #create a matrix for centers\n",
    "    final_centers = [np.zeros(d)] * K\n",
    "    #centers = np.asarray(centers)\n",
    "    centers = np.zeros((K,d))\n",
    "    #print(centers.shape)\n",
    "    #print(X_train.shape)\n",
    "    \n",
    "    #if center still change after 10000 times, force stop\n",
    "    itera = 10000\n",
    "    while(itera!=0):\n",
    "        print(itera)\n",
    "        \n",
    "        #initial k centers\n",
    "        if itera == 10000:\n",
    "            #print(\"111111111111\")\n",
    "            ind = random.sample(range(0,len_train),K)\n",
    "            #print(ind)\n",
    "            ii = 0\n",
    "            for i in ind:\n",
    "                centers[ii,:] = X_train[i,:]\n",
    "                ii = ii + 1\n",
    "                #print(X_train[i].shape)\n",
    "                #centers[i] = X_train[i]\n",
    "        #print(\"2222222222222\")\n",
    "        \n",
    "        #update centers  \n",
    "        new_centers = update_centroids(centers, X_train)\n",
    "        #print(\"333333333333333333\")\n",
    "        \n",
    "        print(type(new_centers),type(centers),new_centers.shape)       \n",
    "        if ((new_centers == centers).all()):\n",
    "            #print(\"endendendendendend\")\n",
    "            break\n",
    "        #count = 0\n",
    "        #for i in range(K):\n",
    "        #    if ((new_centers[i]==centers[i]).all()):\n",
    "        #        count = count + 1\n",
    "        #if count == K:\n",
    "        #    break\n",
    "        #print(\"4444444444444444\")\n",
    "        centers = new_centers\n",
    "        itera = itera - 1\n",
    "        \n",
    "    final_centers = new_centers\n",
    "    \n",
    "    return final_centers\n",
    "    #return new_centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, N\n",
    "\n",
    "# mean of feature vectors\n",
    "mean_vector = np.mean(X_train,axis = 0)\n",
    "\n",
    "# covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    '''树的节点的类\n",
    "    '''\n",
    "    def __init__(self, fea=-1, value=None, results=None, right=None, left=None):\n",
    "        self.fea = fea  # 用于切分数据集的属性的列索引值\n",
    "        self.value = value  # 设置划分的值\n",
    "        self.results = results  # 存储叶节点所属的类别\n",
    "        self.right = right  # 右子树\n",
    "        self.left = left  # 左子树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(data):\n",
    "    '''构建树\n",
    "    input:  data(list):训练样本\n",
    "    output: node:树的根结点\n",
    "    '''\n",
    "    # 构建决策树，函数返回该决策树的根节点\n",
    "    if len(data) == 0:\n",
    "        return node()\n",
    "    # 1、计算当前的Gini指数\n",
    "    currentGini = cal_gini_index(data)\n",
    "    bestGain = 0.0\n",
    "    bestCriteria = None  # 存储最佳切分属性以及最佳切分点\n",
    "    bestSets = None  # 存储切分后的两个数据集\n",
    "    feature_num = len(data[0]) - 1  # 样本中特征的个数\n",
    "    # 2、找到最好的划分\n",
    "    for fea in range(0, feature_num):\n",
    "        # 2.1、取得fea特征处所有可能的取值\n",
    "        feature_values = {}  # 在fea位置处可能的取值\n",
    "        for sample in data:  # 对每一个样本\n",
    "            feature_values[sample[fea]] = 1  # 存储特征fea处所有可能的取值\n",
    "        # 2.2、针对每一个可能的取值，尝试将数据集划分，并计算Gini指数\n",
    "        for value in feature_values.keys():  # 遍历该属性的所有切分点\n",
    "            # 2.2.1、 根据fea特征中的值value将数据集划分成左右子树\n",
    "            (set_1, set_2) = split_tree(data, fea, value)\n",
    "            # 2.2.2、计算当前的Gini指数\n",
    "            nowGini = float(len(set_1) * cal_gini_index(set_1) + \n",
    "                             len(set_2) * cal_gini_index(set_2)) / len(data)\n",
    "            # 2.2.3、计算Gini指数的增加量\n",
    "            gain = currentGini - nowGini\n",
    "            # 2.2.4、判断此划分是否比当前的划分更好\n",
    "            if gain > bestGain and len(set_1) > 0 and len(set_2) > 0:\n",
    "                bestGain = gain\n",
    "                bestCriteria = (fea, value)\n",
    "                bestSets = (set_1, set_2)\n",
    "    # 3、判断划分是否结束\n",
    "    if bestGain > 0:\n",
    "        right = build_tree(bestSets[0])\n",
    "        left = build_tree(bestSets[1])\n",
    "        return node(fea=bestCriteria[0], value=bestCriteria[1], \n",
    "                    right=right, left=left)\n",
    "    else:\n",
    "        return node(results=(label_uniq_cnt(data)).item(0))  # 返回当前的类别标签作为最终的类别标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_gini_index(data):\n",
    "    '''计算给定数据集的Gini指数\n",
    "    input:  data(list):树中\n",
    "    output: gini(float):Gini指数\n",
    "    '''\n",
    "    total_sample = len(data)  # 样本的总个数\n",
    "    if len(data) == 0:\n",
    "        return 0  \n",
    "    label_counts = label_uniq_cnt(data)  # 统计数据集中不同标签的个数\n",
    "    # 计算数据集的Gini指数\n",
    "    gini = 0\n",
    "    for label in range (len(label_counts)):\n",
    "        gini = gini + pow(label_counts[label], 2) \n",
    "    gini = 1 - float(gini) / pow(total_sample, 2)\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tree(data, fea, value):\n",
    "    '''根据特征fea中的值value将数据集data划分成左右子树\n",
    "    input:  data(list):数据集\n",
    "            fea(int):待分割特征的索引\n",
    "            value(float):待分割的特征的具体值\n",
    "    output: (set1,set2)(tuple):分割后的左右子树\n",
    "    '''\n",
    "    set_1 = []\n",
    "    set_2 = []\n",
    "    for x in data:\n",
    "        if x[fea] >= value:\n",
    "            set_1.append(x)\n",
    "        else:\n",
    "            set_2.append(x)\n",
    "    return (set_1, set_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sample, tree):\n",
    "    '''对每一个样本sample进行预测\n",
    "    input:  sample(list):需要预测的样本\n",
    "            tree(类):构建好的分类树\n",
    "    output: tree.results:所属的类别\n",
    "    '''\n",
    "    # 1、只是树根\n",
    "    if tree.results != None:\n",
    "        return tree.results\n",
    "    else:\n",
    "    # 2、有左右子树\n",
    "        val_sample = sample[tree.fea]\n",
    "        branch = None\n",
    "        if val_sample >= tree.value:\n",
    "            branch = tree.right\n",
    "        else:\n",
    "            branch = tree.left\n",
    "        return predict(sample, branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_training(data_train, trees_num):\n",
    "    '''构建随机森林\n",
    "    input:  data_train(list):训练数据\n",
    "            trees_num(int):分类树的个数\n",
    "    output: trees_result(list):每一棵树的最好划分\n",
    "            trees_feature(list):每一棵树中对原始特征的选择\n",
    "    '''\n",
    "    trees_result = []  # 构建好每一棵树的最好划分\n",
    "    trees_feature = []\n",
    "    n = np.shape(data_train)[1]  # 样本的维数\n",
    "    if n > 2:\n",
    "        k = int(log(n - 1, 2)) + 1 # 设置特征的个数\n",
    "    else:\n",
    "        k = 1\n",
    "    # 开始构建每一棵树\n",
    "    for i in range(trees_num):\n",
    "        # 1、随机选择m个样本, k个特征\n",
    "        data_samples, feature = choose_samples(data_train, k)\n",
    "        # 2、构建每一棵分类树\n",
    "        tree = build_tree(data_samples)\n",
    "        # 3、保存训练好的分类树\n",
    "        trees_result.append(tree)\n",
    "        # 4、保存好该分类树使用到的特征\n",
    "        trees_feature.append(feature)\n",
    "   \n",
    "    return trees_result, trees_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_samples(data, k):\n",
    "    '''\n",
    "    input:  data(list):原始数据集\n",
    "            k(int):选择特征的个数\n",
    "    output: data_samples(list):被选择出来的样本\n",
    "            feature(list):被选择的特征index\n",
    "    '''\n",
    "    m, n = np.shape(data)  # 样本的个数和样本特征的个数\n",
    "    # 1、选择出k个特征的index\n",
    "    feature = []\n",
    "    for j in range(k):\n",
    "        feature.append(random.randint(0, n - 2))  # n-1列是标签\n",
    "    # 2、选择出m个样本的index\n",
    "    index = []\n",
    "    for i in range(m):\n",
    "        index.append(random.randint(0, m - 1))\n",
    "    # 3、从data中选择出m个样本的k个特征，组成数据集data_samples\n",
    "    data_samples = []\n",
    "    for i in range(m):\n",
    "        data_tmp = []\n",
    "        for fea in feature:\n",
    "            data_tmp.append(data[index[i]][fea])\n",
    "        data_tmp.append(data[index[i]][-1])\n",
    "        data_samples.append(data_tmp)\n",
    "    return data_samples, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_uniq_cnt(data):\n",
    "    data = np.asarray(data)\n",
    "    classes = data[:,-1]\n",
    "#     print(classes)\n",
    "    index_elements, counts_elements = np.unique(classes, return_counts=True)\n",
    "    if len(counts_elements) > 1:\n",
    "        return counts_elements\n",
    "    else:\n",
    "        return index_elements   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([[1,1],[1,1],[2,1],[3,2],[4,3]])\n",
    "t2 = np.array([[1,1],[1,1]])\n",
    "label_uniq_cnt(t2)\n",
    "# cal_gini_index(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_forest_training(data_train, trees_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X_train[0:1000, :]\n",
    "Y1 = Y_train[0:1000]\n",
    "\n",
    "Y1 = np.reshape(Y1,(-1, 1))\n",
    "data_train = np.concatenate((X1,Y1),axis = 1)\n",
    "\n",
    "trees_num = 2\n",
    "\n",
    "# predict(X1,Y1, 2)\n",
    "# random_forest_training(data_train, trees_num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(x_test, data_train, trees_num):\n",
    "    trees, features = random_forest_training(data_train, trees_num)\n",
    "    ans = []\n",
    "    for tree in trees:\n",
    "        ans.append(predict(x_test, tree))\n",
    "    print(\"prediction is :\" ,ans)\n",
    "    return np.asarray(ans)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction is : [11.0, 11.0, 11.0, 11.0, 10.0, 7.0, 11.0, 7.0, 10.0, 11.0]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "rf(X_test[0], data_train, 10)\n",
    "print(Y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def confusMax(Y_pred, Y_test):\n",
    "    num_class = len(np.unique(Y_test))\n",
    "#     print(np.unique(Y_test))\n",
    "    Y_hold = Y_test * num_class + Y_pred\n",
    "#     Y_hold = np.zeros(num_class * num_class)\n",
    "    Y_bin = np.arange(num_class * num_class + 1)\n",
    "    con_matrx = np.asarray(np.histogram(Y_hold, bins=Y_bin)[0]).reshape(num_class, num_class)\n",
    "#     return np.histogram(Y_hold, bins=Y_bin)\n",
    "    return con_matrx\n",
    "#     print(len(hold))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0, 795,   0,   0,   0,   0,  12,   0,   0,   0,   0],\n",
       "       [  0,   0, 747,   0,   0,   0,   0,   0,   0,   0,  11],\n",
       "       [  0,   0,   0, 726,   0,   4,   1,   0,   1,   0,   0],\n",
       "       [  0,   0,   0,   2, 721,   2,   0,   0,   0,   0,   0],\n",
       "       [  0,   1,   0,   5,   1, 712,   1,   0,   6,   0,   0],\n",
       "       [  1,  12,   0,   2,   0,   0, 711,   0,   1,   7,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 754,   0,   0,   0],\n",
       "       [  0,   2,   0,   1,   2,   7,   5,   0, 700,   0,   0],\n",
       "       [  0,   3,   0,   3,   0,   0,  22,   0,   0, 721,   0],\n",
       "       [  0,   0,  26,   0,   0,   0,   0,   0,   0,   0, 704]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y1 = KNN(X_train,X_test,Y_train,5)\n",
    "\n",
    "confusMax(Y1, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall(y_true,y_pred):\n",
    "    num_class = len(np.unique(Y_test))\n",
    "    print(num_class)\n",
    "    con_matrix = confusMax(y_pred,y_true)\n",
    "    sum_recall = 0.0\n",
    "    for j in range(num_class):\n",
    "        TP = 0\n",
    "        FN = 0\n",
    "        for i in range(num_class):\n",
    "            if(i == j):\n",
    "                TP += con_matrix[i][j]\n",
    "            else: \n",
    "                FN += con_matrix[i][j]\n",
    "        if TP == 0:\n",
    "            sum_recall += 0\n",
    "        else:             \n",
    "            sum_recall += (TP/(TP + FN))\n",
    "    recall = sum_recall/num_class\n",
    "    return recall\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "#      \"\"\"\n",
    "#     :type y_true: numpy.ndarray\n",
    "#     :type y_pred: numpy.ndarray\n",
    "#     :rtype: float\n",
    "#     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8921579871684698"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_class = len(np.unique(Y_test))\n",
    "\n",
    "Recall(Y_test, Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision(y_true,y_pred):\n",
    "    num_class = len(np.unique(Y_test))\n",
    "    con_matrix = confusMax(y_pred,y_true)\n",
    "#     num = len(con_matrix)\n",
    "#     print(num)\n",
    "    sum_prec = 0.0\n",
    "    for i in range(num_class):\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        for j in range(num_class):\n",
    "            if(i == j):\n",
    "                TP += con_matrix[i][j]\n",
    "            else: \n",
    "                FP += con_matrix[i][j]\n",
    "        if TP == 0:\n",
    "            sum_prec += 0\n",
    "        else:             \n",
    "            sum_prec += (TP/(TP + FP))\n",
    "        prec = sum_prec/num_class\n",
    "    return prec\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8917796237059065"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Precision(Y_test, Y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Predicitve_Analytics.py\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def Accuracy(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \n",
    "    \"\"\"\n",
    "    l = len(y_true)\n",
    "    count = 0\n",
    "    for i in range(l):\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            count = count + 1\n",
    "    acc = count/l\n",
    "    return acc\n",
    "\n",
    "def Recall(y_true,y_pred):\n",
    "     \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "\n",
    "def Precision(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "def WCSS(Clusters):\n",
    "    \"\"\"\n",
    "    :Clusters List[numpy.ndarray]\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    \n",
    "def ConfusionMatrix(y_true,y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\"  \n",
    "\n",
    "def KNN(X_train,X_test,Y_train,N):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    :typr N: constant\n",
    "    \n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    cos_sim = KNN_find_similarity(X_train, X_test)\n",
    "    Y_pred = KNN_predict(cos_sim,N,Y_train)\n",
    "    \n",
    "    return Y_pred\n",
    "        \n",
    "def RandomForest(X_train,Y_train,X_test):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "def PCA(X_train,N):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type N: int\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "def Kmeans(X_train,N):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type N: int\n",
    "    :rtype: List[numpy.ndarray]\n",
    "    \"\"\"\n",
    "    centroids = find_centroids(X_train,N)\n",
    "    return centroids\n",
    "\n",
    "def SklearnSupervisedLearning(X_train,Y_train,X_test):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: List[numpy.ndarray] \n",
    "    \"\"\"\n",
    "\n",
    "def SklearnVotingClassifier(X_train,Y_train,X_test):\n",
    "    \n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: List[numpy.ndarray] \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "#\"\"\"\n",
    "#Create your own custom functions for Matplotlib visualization of hyperparameter search. \n",
    "#Make sure that plots are labeled and proper legends are used\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time of KNN 33.30502200126648 .\n",
      "Accuracy of KNN 0.9841289219875473 .\n",
      "============================\n",
      "10000\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> (11, 48)\n",
      "9999\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> (11, 48)\n",
      "Runtime of K-Means:  0.1835639476776123 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuxuanzhang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    }
   ],
   "source": [
    "len_train = len(Y_train)\n",
    "len_test = len(Y_test)\n",
    "\n",
    "## KNN\n",
    "K_knn = 11\n",
    "\n",
    "s1 = time.time()\n",
    "Y_pred_knn = KNN(X_train,X_test,Y_train,K_knn)\n",
    "e1 = time.time()\n",
    "\n",
    "#Y_pred_knn = np.asarray(Y_pred_knn)\n",
    "#print(Y_pred_knn.shape)\n",
    "#print(Y_test.shape)\n",
    "#acc_knn = Accuracy(Y_test, Y_pred_knn)\n",
    "#print(acc_knn)\n",
    "acc_knn = Accuracy(Y_test,Y_pred_knn)\n",
    "\n",
    "print(\"Running time of KNN\",e1-s1,\".\")\n",
    "print(\"Accuracy of KNN\",acc_knn,\".\")\n",
    "print(\"============================\")\n",
    "\n",
    "## K-Means\n",
    "K_kmeans = 11\n",
    "\n",
    "s2 = time.time()\n",
    "centroids = Kmeans(X_train,K_kmeans)\n",
    "e2 = time.time()\n",
    "print(\"Runtime of K-Means: \",e2-s2,\"s.\")\n",
    "#print(centroids)\n",
    "\n",
    "## PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [np.array([1,2,3,4])]*5\n",
    "print(a)\n",
    "b = np.asarray(a)\n",
    "print(b)\n",
    "print(b.shape)\n",
    "aa = np.sum(np.square(a),axis = 1)\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.zeros((3,2))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n",
      "[[0. 0. 0. 0.]\n",
      " [1. 2. 3. 4.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4],[2,3,4,5],[3,4,5,6],[4,5,6,7],[5,6,7,8]])\n",
    "print(a.shape)\n",
    "x = np.zeros((6,4))\n",
    "x[1,:] = a[0]\n",
    "print(x)\n",
    "\n",
    "\n",
    "#print(a[:,0])\n",
    "#print(a.max(axis=0))\n",
    "b = a.argmax(axis=0)\n",
    "#print(b[0])\n",
    "\n",
    "aaa = []*11\n",
    "aaa.append([1,2,3])\n",
    "aaa.append([222])\n",
    "aaa.append([3,2,1])\n",
    "#print(aaa[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.96222509e-01 5.46346345e-01 6.46898682e-01 8.38899954e-01\n",
      "  7.27504165e-01 7.83784611e-01 5.29478346e-01 5.29326875e-01\n",
      "  5.28742346e-01 5.47212657e-01 5.47290494e-01 5.47474042e-01\n",
      "  1.58367340e-02 2.03587274e-02 6.42754199e-02 1.57654043e-02\n",
      "  3.56626558e-02 4.78043144e-02 5.32182908e-01 5.32177568e-01\n",
      "  5.32247871e-01 5.33635662e-01 5.33666652e-01 5.33752106e-01\n",
      "  5.41685345e-01 5.62270157e-01 4.52617717e-01 5.43255924e-01\n",
      "  5.14683908e-01 5.86250793e-01 3.22484271e-01 3.37697482e-01\n",
      "  3.28006638e-01 1.94725347e-01 1.97781648e-01 2.00199773e-01\n",
      "  5.70687900e-04 3.75546138e-02 6.60251842e-02 3.49249768e-04\n",
      "  4.87408056e-02 7.45192054e-02 3.72725076e-01 4.23218629e-01\n",
      "  4.32447952e-01 3.24090481e-01 3.52505404e-01 3.16465685e-01\n",
      "  2.00000000e+00]\n",
      " [5.96065939e-01 5.43367815e-01 6.41493724e-01 8.38773637e-01\n",
      "  7.16552764e-01 7.81160565e-01 7.01563656e-01 7.01586333e-01\n",
      "  7.01451618e-01 5.42056622e-01 5.42226998e-01 5.42502400e-01\n",
      "  1.67388036e-02 2.00252471e-02 6.43814050e-02 1.64291404e-02\n",
      "  3.73373500e-02 5.26771622e-02 5.78156411e-01 5.78153134e-01\n",
      "  5.78245306e-01 5.78768468e-01 5.78802070e-01 5.78885373e-01\n",
      "  5.42500802e-01 5.53808230e-01 4.51919228e-01 5.43988611e-01\n",
      "  5.06457971e-01 5.86665807e-01 3.19023512e-01 3.34385360e-01\n",
      "  3.24740858e-01 1.97015664e-01 2.00197917e-01 2.02595651e-01\n",
      "  2.40780993e-04 3.55199979e-02 6.45403286e-02 2.08563800e-04\n",
      "  4.55265605e-02 7.50641142e-02 3.61802082e-01 4.11284355e-01\n",
      "  4.18886633e-01 3.30090061e-01 3.58567327e-01 3.22426329e-01\n",
      "  9.00000000e+00]\n",
      " [5.96424254e-01 5.46046914e-01 6.47118393e-01 8.39214997e-01\n",
      "  7.27894088e-01 7.85873381e-01 7.24488513e-01 7.24381265e-01\n",
      "  7.24007559e-01 5.63341663e-01 5.63423172e-01 5.63536417e-01\n",
      "  1.59172146e-02 1.95576853e-02 5.83981586e-02 1.57572273e-02\n",
      "  3.56469888e-02 4.93897960e-02 5.33742477e-01 5.33737032e-01\n",
      "  5.33825076e-01 5.34557139e-01 5.34590365e-01 5.34667818e-01\n",
      "  5.41576022e-01 5.60536745e-01 4.53559774e-01 5.43292448e-01\n",
      "  5.13733190e-01 5.89388775e-01 2.97476771e-01 3.12581630e-01\n",
      "  3.04100314e-01 2.09371398e-01 2.12705144e-01 2.15468351e-01\n",
      "  2.04538575e-04 3.35860419e-02 6.48551836e-02 2.06533906e-04\n",
      "  4.63107494e-02 7.30324541e-02 3.71907763e-01 4.22361143e-01\n",
      "  4.31167107e-01 3.17144998e-01 3.45522388e-01 3.09779744e-01\n",
      "  6.00000000e+00]\n",
      " [5.95654593e-01 5.43311078e-01 6.44436169e-01 8.39087478e-01\n",
      "  7.17685593e-01 7.80774379e-01 2.19330693e-01 2.19283543e-01\n",
      "  2.18463564e-01 1.15283898e-01 1.15257929e-01 1.15447206e-01\n",
      "  1.58362418e-02 1.94415774e-02 5.84935626e-02 1.58234568e-02\n",
      "  3.57475320e-02 4.91952530e-02 5.48196255e-01 5.48193347e-01\n",
      "  5.48284785e-01 5.49736896e-01 5.49768076e-01 5.49862337e-01\n",
      "  5.42705533e-01 5.52307352e-01 4.52459827e-01 5.44032303e-01\n",
      "  5.07423812e-01 5.88723316e-01 2.95638776e-01 3.10868400e-01\n",
      "  3.02249670e-01 1.65876757e-01 1.68434128e-01 1.70109678e-01\n",
      "  2.38455194e-04 3.48545863e-02 6.39812581e-02 2.22929410e-04\n",
      "  4.81427579e-02 7.62567994e-02 3.86064616e-01 4.38018043e-01\n",
      "  4.48862183e-01 3.27717437e-01 3.56153432e-01 3.19782129e-01\n",
      "  1.10000000e+01]\n",
      " [5.96358047e-01 5.43156109e-01 6.43222576e-01 8.39022871e-01\n",
      "  7.16240783e-01 7.81179697e-01 7.41172041e-01 7.41211280e-01\n",
      "  7.41039976e-01 7.25251968e-01 7.25505103e-01 7.25822529e-01\n",
      "  1.25409251e-02 1.52174755e-02 4.46524183e-02 1.25623614e-02\n",
      "  2.76515446e-02 3.70060808e-02 3.28606659e-01 3.28598851e-01\n",
      "  3.28595846e-01 3.29565143e-01 3.29580593e-01 3.29576969e-01\n",
      "  5.42392332e-01 5.53114103e-01 4.51705567e-01 5.43930599e-01\n",
      "  5.04208308e-01 5.86144763e-01 3.26606807e-01 3.42089240e-01\n",
      "  3.32243318e-01 2.30585723e-01 2.34465682e-01 2.37673338e-01\n",
      "  1.91498968e-04 3.00108451e-02 5.91048276e-02 1.74884183e-04\n",
      "  4.03672198e-02 6.74233907e-02 3.71025992e-01 4.21229478e-01\n",
      "  4.29770232e-01 3.27562256e-01 3.55974752e-01 3.19881046e-01\n",
      "  4.49866429e+00]\n",
      " [5.96242946e-01 5.46330788e-01 6.49257066e-01 8.39181025e-01\n",
      "  7.28284135e-01 7.84683276e-01 5.05478102e-01 5.05323808e-01\n",
      "  5.04601093e-01 5.83937282e-01 5.84024452e-01 5.84184648e-01\n",
      "  1.58136966e-02 1.92813247e-02 6.14478609e-02 1.55616672e-02\n",
      "  3.55251941e-02 4.87247419e-02 5.07949718e-01 5.07946165e-01\n",
      "  5.08000422e-01 5.08177594e-01 5.08205597e-01 5.08264547e-01\n",
      "  5.41726054e-01 5.61620177e-01 4.53933217e-01 5.43330760e-01\n",
      "  5.14510290e-01 5.89121647e-01 2.97391329e-01 3.12457533e-01\n",
      "  3.04015666e-01 2.15865432e-01 2.19317572e-01 2.22222191e-01\n",
      "  2.11473248e-04 3.12372478e-02 6.35648186e-02 2.08116288e-04\n",
      "  4.35256405e-02 7.18314009e-02 3.62445208e-01 4.11926508e-01\n",
      "  4.19686207e-01 3.27450949e-01 3.55916944e-01 3.19833430e-01\n",
      "  1.00000000e+01]\n",
      " [5.96119369e-01 5.43379281e-01 6.41935046e-01 8.38882768e-01\n",
      "  7.17156734e-01 7.80243159e-01 8.07476417e-01 8.07514530e-01\n",
      "  8.07479066e-01 6.75229167e-01 6.75452532e-01 6.75791533e-01\n",
      "  1.66186292e-02 1.98105618e-02 6.23477869e-02 1.64926535e-02\n",
      "  3.63960387e-02 5.00455240e-02 5.60347212e-01 5.60344744e-01\n",
      "  5.60435575e-01 5.60399978e-01 5.60435321e-01 5.60524090e-01\n",
      "  5.42351069e-01 5.54300942e-01 4.53026456e-01 5.43919396e-01\n",
      "  5.06258315e-01 5.86633744e-01 3.16862086e-01 3.32178880e-01\n",
      "  3.22717697e-01 2.21602549e-01 2.25265157e-01 2.28244545e-01\n",
      "  2.35304825e-04 3.18236430e-02 6.32063220e-02 2.11796214e-04\n",
      "  4.58531237e-02 7.31377340e-02 3.70784302e-01 4.21143961e-01\n",
      "  4.29770570e-01 3.26802946e-01 3.55318651e-01 3.19172975e-01\n",
      "  8.00000000e+00]\n",
      " [5.96574123e-01 5.46249215e-01 6.46831288e-01 8.39063621e-01\n",
      "  7.27625065e-01 7.84116986e-01 8.74272241e-01 8.74177404e-01\n",
      "  8.73987030e-01 9.23348286e-01 9.23589750e-01 9.23849072e-01\n",
      "  1.52246977e-02 1.87250440e-02 5.41573844e-02 1.51149256e-02\n",
      "  3.38608862e-02 4.59784876e-02 4.62492978e-01 4.62488052e-01\n",
      "  4.62538727e-01 4.62423128e-01 4.62446136e-01 4.62489108e-01\n",
      "  5.41529376e-01 5.60870263e-01 4.56209073e-01 5.43279248e-01\n",
      "  5.12631252e-01 5.87790851e-01 3.22707581e-01 3.37939987e-01\n",
      "  3.28297630e-01 2.59967465e-01 2.64298890e-01 2.68264602e-01\n",
      "  2.14527881e-04 2.96534727e-02 6.30522330e-02 2.09518009e-04\n",
      "  4.25955067e-02 7.18102371e-02 3.70417197e-01 4.20708709e-01\n",
      "  4.29192736e-01 3.18347522e-01 3.46620800e-01 3.10688435e-01\n",
      "  7.00000000e+00]\n",
      " [5.96098744e-01 5.43424505e-01 6.41274091e-01 8.38401209e-01\n",
      "  7.16300892e-01 7.79524338e-01 7.69291316e-01 7.69321376e-01\n",
      "  7.69273702e-01 7.41364988e-01 7.41624673e-01 7.42004592e-01\n",
      "  2.03481028e-02 2.53435348e-02 7.68515762e-02 1.99995939e-02\n",
      "  4.54781874e-02 6.23386234e-02 7.78459919e-01 7.78455033e-01\n",
      "  7.78631972e-01 7.79428668e-01 7.79479294e-01 7.79657633e-01\n",
      "  5.42547135e-01 5.54993596e-01 4.53183835e-01 5.44202590e-01\n",
      "  5.06021746e-01 5.87211927e-01 3.41260030e-01 3.56713741e-01\n",
      "  3.46149760e-01 2.09365396e-01 2.12773959e-01 2.15485313e-01\n",
      "  5.32084378e-04 3.96980392e-02 6.68737176e-02 3.20582726e-04\n",
      "  5.04758516e-02 8.01265195e-02 3.53149680e-01 4.01674053e-01\n",
      "  4.07884581e-01 3.30907849e-01 3.59488344e-01 3.23046592e-01\n",
      "  4.50133333e+00]\n",
      " [5.96351017e-01 5.46063794e-01 6.48507686e-01 8.39068896e-01\n",
      "  7.28621980e-01 7.84535751e-01 7.71378099e-01 7.71277071e-01\n",
      "  7.70891184e-01 5.38295635e-01 5.38359949e-01 5.38514769e-01\n",
      "  1.58084926e-02 1.95510672e-02 6.05134751e-02 1.53602545e-02\n",
      "  3.43553570e-02 4.88055646e-02 4.84156941e-01 4.84145819e-01\n",
      "  4.84187214e-01 4.85705594e-01 4.85731470e-01 4.85772994e-01\n",
      "  5.41471145e-01 5.60921805e-01 4.55630779e-01 5.43310255e-01\n",
      "  5.15339407e-01 5.87587555e-01 3.20418993e-01 3.35660144e-01\n",
      "  3.26101935e-01 2.16736318e-01 2.20192444e-01 2.23147398e-01\n",
      "  2.10254520e-04 3.49595808e-02 6.15252585e-02 2.02499758e-04\n",
      "  4.17966610e-02 7.12451642e-02 3.51670659e-01 3.99883764e-01\n",
      "  4.06119168e-01 3.31976255e-01 3.60452024e-01 3.24418858e-01\n",
      "  1.00000000e+00]\n",
      " [5.96351305e-01 5.46355295e-01 6.47500219e-01 8.39071659e-01\n",
      "  7.28290394e-01 7.84812768e-01 6.91381700e-01 6.91254091e-01\n",
      "  6.90824880e-01 6.66814506e-01 6.66937835e-01 6.67112847e-01\n",
      "  1.49792230e-02 1.86667868e-02 5.85593001e-02 1.46762201e-02\n",
      "  3.27874432e-02 4.47713737e-02 4.54467170e-01 4.54457705e-01\n",
      "  4.54482952e-01 4.55277257e-01 4.55302127e-01 4.55342710e-01\n",
      "  5.41573989e-01 5.61452307e-01 4.54041041e-01 5.43303751e-01\n",
      "  5.13892027e-01 5.89203909e-01 3.23357248e-01 3.38584881e-01\n",
      "  3.28869464e-01 2.21002307e-01 2.24550090e-01 2.27561983e-01\n",
      "  2.01452544e-04 3.32349524e-02 6.03985237e-02 2.10348392e-04\n",
      "  4.31603815e-02 7.21392774e-02 3.65730505e-01 4.15446140e-01\n",
      "  4.23708576e-01 3.24808685e-01 3.53201750e-01 3.17082751e-01\n",
      "  3.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "    \n",
    "kmeans = KMeans(n_clusters=11).fit(train_df)\n",
    "centroids = kmeans.cluster_centers_\n",
    "print(centroids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(X_train,Y_train)\n",
    "a = Accuracy(Y_test,knn.predict(X_test))\n",
    "print(a,\"==========11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
